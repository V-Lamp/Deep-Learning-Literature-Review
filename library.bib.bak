% This file was created with JabRef 2.7.1.
% Encoding: UTF8

@ARTICLE{Arel2010,
  author = {Arel, Itamar and Rose, DC and Karnowski, TP},
  title = {{Deep machine learning-a new frontier in artificial intelligence
	research}},
  journal = {Comput. Intell. \ldots},
  year = {2010},
  pages = {13--18},
  number = {November},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Arel, Rose, Karnowski_2010_Deep machine learning-a new frontier in artificial intelligence research.pdf:pdf},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5605630}
}

@ARTICLE{Bengio2013,
  author = {Bengio, Yoshua},
  title = {{Deep Learning of Representations: Looking Forward}},
  year = {2013},
  month = {\#may\#},
  abstract = {Deep learning research aims at discovering learning algorithms that
	discover multiple levels of distributed representations, with higher
	levels representing more abstract concepts. Although the study of
	deep learning has already led to impressive theoretical results,
	learning algorithms and breakthrough experiments, several challenges
	lie ahead. This paper proposes to examine some of these challenges,
	centering on the questions of scaling deep learning algorithms to
	much larger models and datasets, reducing optimization difficulties
	due to ill-conditioning or local minima, designing more efficient
	and powerful inference and sampling procedures, and learning to disentangle
	the factors of variation underlying the observed data. It also proposes
	a few forward-looking research directions aimed at overcoming these
	challenges.},
  archiveprefix = {arXiv},
  arxivid = {1305.0445},
  eprint = {1305.0445},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2013_Deep Learning of Representations Looking Forward.pdf:pdf},
  url = {http://arxiv.org/abs/1305.0445}
}

@ARTICLE{Bengio2009,
  author = {Bengio, Yoshua},
  title = {{Learning deep architectures for AI}},
  journal = {Found. trends® Mach. Learn.},
  year = {2009},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2009_Learning deep architectures for AI.pdf:pdf},
  url = {http://dl.acm.org/citation.cfm?id=1658424}
}

@ARTICLE{Bengio2012,
  author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  title = {{Representation Learning: A Review and New Perspectives}},
  journal = {PAMI},
  year = {2012},
  volume = {35},
  pages = {1--30},
  number = {1993},
  month = {\#jun\#},
  abstract = {The success of machine learning algorithms generally depends on data
	representation, and we hypothesize that this is because different
	representations can entangle and hide more or less the different
	explanatory factors of variation behind the data. Although specific
	domain knowledge can be used to help design representations, learning
	with generic priors can also be used, and the quest for AI is motivating
	the design of more powerful representation-learning algorithms implementing
	such priors. This paper reviews recent work in the area of unsupervised
	feature learning and deep learning, covering advances in probabilistic
	models, auto-encoders, manifold learning, and deep networks. This
	motivates longer-term unanswered questions about the appropriate
	objectives for learning good representations, for computing representations
	(i.e., inference), and the geometrical connections between representation
	learning, density estimation and manifold learning.},
  archiveprefix = {arXiv},
  arxivid = {1206.5538},
  doi = {10.1109/TPAMI.2013.50},
  eprint = {1206.5538},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, Courville, Vincent_2012_Representation Learning A Review and New Perspectives.pdf:pdf},
  issn = {1939-3539},
  pmid = {23787338},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/23787338 http://arxiv.org/abs/1206.5538}
}

@ARTICLE{Bengio2007,
  author = {Bengio, Yoshua and LeCun, Y},
  title = {{Scaling learning algorithms towards AI}},
  journal = {Large-scale kernel Mach.},
  year = {2007},
  pages = {1--41},
  number = {1},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, LeCun_2007_Scaling learning algorithms towards AI.pdf:pdf},
  url = {http://www.iro.umontreal.ca/$\sim$lisa/bib/pub_subject/language/pointeurs/bengio+lecun-chapter2007.pdf}
}

@INPROCEEDINGS{Boureau2010,
  author = {Boureau, Y-Lan and Bach, Francis and LeCun, Yann and Ponce, Jean},
  title = {{Learning mid-level features for recognition}},
  booktitle = {2010 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit.},
  year = {2010},
  pages = {2559--2566},
  month = {\#jun\#},
  publisher = {IEEE},
  abstract = {Many successful models for scene or object recognition transform low-level
	descriptors (such as Gabor filter responses, or SIFT descriptors)
	into richer representations of intermediate complexity. This process
	can often be broken down into two steps: (1) a coding step, which
	performs a pointwise transformation of the descriptors into a representation
	better adapted to the task, and (2) a pooling step, which summarizes
	the coded features over larger neighborhoods. Several combinations
	of coding and pooling schemes have been proposed in the literature.
	The goal of this paper is threefold. We seek to establish the relative
	importance of each step of mid-level feature extraction through a
	comprehensive cross evaluation of several types of coding modules
	(hard and soft vector quantization, sparse coding) and pooling schemes
	(by taking the average, or the maximum), which obtains state-of-the-art
	performance or better on several recognition benchmarks. We show
	how to improve the best performing coding scheme by learning a supervised
	discriminative dictionary for sparse coding. We provide theoretical
	and empirical insight into the remarkable performance of max pooling.
	By teasing apart components shared by modern mid-level feature extractors,
	our approach aims to facilitate the design of better recognition
	architectures.},
  doi = {10.1109/CVPR.2010.5539963},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boureau et al._2010_Learning mid-level features for recognition.pdf:pdf},
  isbn = {978-1-4244-6984-0},
  issn = {1063-6919},
  keywords = {Convolutional codes,Dictionaries,Feature extraction,Gabor filter responses,Gabor
	filters,Image classification,Image coding,Image representation,Layout,Object
	recognition,SIFT descriptors,Vector quantization,coding step,feature
	extraction,learning (artificial intelligence),low level descriptors,mid
	level features learning,object recognition,pointwise transformation,pooling
	step,sparse coding,vector quantisation,vector quantization},
  shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539963}
}

@ARTICLE{Deng2013,
  author = {Deng, Li and Yu, Dong},
  title = {{Deep Learning: Methods and Applications}},
  journal = {Found. Trends Signal Process.},
  year = {2013},
  volume = {7},
  pages = {197----387},
  abstract = {This book is aimed to provide an overview of general deep learning
	methodology and its applications to a variety of signal and information
	processing tasks. The application areas are chosen with the following
	three criteria: 1) expertise or knowledge of the authors; 2) the
	application areas that have already been transformed by the successful
	use of deep learning technology, such as speech recognition and computer
	vision; and 3) the application areas that have the potential to be
	impacted significantly by deep learning and that have gained concentrated
	research efforts, including natural language and text processing,
	information retrieval, and multimodal information processing empowered
	by multi-task deep learning. In Chapter 1, we provide the background
	of deep learning, as intrinsically connected to the use of multiple
	layers of nonlinear transformations to derive features from the sensory
	signals such as speech and visual images. In the most recent literature,
	deep learning is embodied also as representation learning, which
	involves a hierarchy of features or concepts where higher-level representations
	of them are defined from lower-level ones and where the same lower-level
	representations help to define higher-level ones. In Chapter 2, a
	brief historical account of deep learning is presented. In particular,
	selected chronological development of speech recognition is used
	to illustrate the recent impact of deep learning that has become
	a dominant technology in speech recognition industry within only
	a few years since the start of a collaboration between academic and
	industrial researchers in applying deep learning to speech recognition.
	In Chapter 3, a three-way classification scheme for a large body
	of work in deep learning is developed. We classify a growing number
	of deep learning techniques into unsupervised, supervised, and hybrid
	categories, and present qualitative descriptions and a literature
	survey for each category. From Chapter 4 to Chapter 6, we discuss
	in detail three popular deep networks and related learning methods,
	one in each category. Chapter 4 is devoted to deep autoencoders as
	a prominent example of the unsupervised deep learning techniques.
	Chapter 5 gives a major example in the hybrid deep network category,
	which is the discriminative feed-forward neural network for supervised
	learning with many layers initialized using layer-by-layer generative,
	unsupervised pre-training. In Chapter 6, deep stacking networks and
	several of the variants are discussed in detail, which exemplify
	the discriminative or supervised deep learning techniques in the
	three-way categorization scheme. In Chapters 7-11, we select a set
	of typical and successful applications of deep learning in diverse
	areas of signal and information processing and of applied artificial
	intelligence. In Chapter 7, we review the applications of deep learning
	to speech and audio processing, with emphasis on speech recognition
	organized according to several prominent themes. In Chapters 8, we
	present recent results of applying deep learning to language modeling
	and natural language processing. Chapter 9 is devoted to selected
	applications of deep learning to information retrieval including
	Web search. In Chapter 10, we cover selected applications of deep
	learning to image object recognition in computer vision. Selected
	applications of deep learning to multi-modal processing and multi-task
	learning are reviewed in Chapter 11. Finally, an epilogue is given
	in Chapter 12 to summarize what we presented in earlier chapters
	and to discuss future challenges and directions.},
  doi = {10.1136/bmj.319.7209.0a},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng, Yu_2013_Deep Learning Methods and Applications.pdf:pdf},
  isbn = {9781405161251},
  issn = {09598138},
  pmid = {10463930}
}

@ARTICLE{Egmont-Petersen2002,
  author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
  title = {{Image processing with neural networks—a review}},
  journal = {Pattern Recognit.},
  year = {2002},
  volume = {35},
  pages = {2279--2301},
  number = {10},
  month = {\#oct\#},
  abstract = {We review more than 200 applications of neural networks in image processing
	and discuss the present and possible future role of neural networks,
	especially feed-forward neural networks, Kohonen feature maps and
	Hopfield neural networks. The various applications are categorised
	into a novel two-dimensional taxonomy for image processing algorithms.
	One dimension specifies the type of task performed by the algorithm:
	preprocessing, data reduction/feature extraction, segmentation, object
	recognition, image understanding and optimisation. The other dimension
	captures the abstraction level of the input data processed by the
	algorithm: pixel-level, local feature-level, structure-level, object-level,
	object-set-level and scene characterisation. Each of the six types
	of tasks poses specific constraints to a neural-based approach. These
	specific conditions are discussed in detail. A synthesis is made
	of unresolved problems related to the application of pattern recognition
	techniques in image processing and specifically to the application
	of neural networks. Finally, we present an outlook into the future
	application of neural networks and relate them to novel developments.},
  doi = {10.1016/S0031-3203(01)00178-9},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels_2002_Image processing with neural networks—a review.pdf:pdf},
  issn = {00313203},
  keywords = {Digital image processing,Feature extraction,Image compression,Image
	understanding,Invariant pattern recognition,Neural networks,Object
	recognition,Optimization,Preprocessing,Segmentation},
  url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789}
}

@ARTICLE{Erhan2010,
  author = {Erhan, Dumitru and Courville, Aaron and Vincent, Pascal and Bengio,
	Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent,
	Pascal and Bengio, Samy},
  title = {{Why Does Unsupervised Pre-training Help Deep Learning ?}},
  journal = {J. Mach. Learn. Res.},
  year = {2010},
  volume = {11},
  pages = {625--660},
  month = {\#mar\#},
  abstract = {Much recent research has been devoted to learning algorithms for deep
	architectures such as Deep Belief Networks and stacks of auto-encoder
	variants, with impressive results obtained in several areas, mostly
	on vision and language data sets. The best results obtained on supervised
	learning tasks involve an unsupervised learning component, usually
	in an unsupervised pre-training phase. Even though these new algorithms
	have enabled training deep models, many questions remain as to the
	nature of this difficult learning problem. The main question investigated
	here is the following: how does unsupervised pre-training work? Answering
	this questions is important if learning in deep architectures is
	to be further improved. We propose several explanatory hypotheses
	and test them through extensive simulations. We empirically show
	the influence of pre-training with respect to architecture depth,
	model capacity, and number of training examples. The experiments
	confirm and clarify the advantage of unsupervised pre-training. The
	results suggest that unsupervised pre-training guides the learning
	towards basins of attraction of minima that support better generalization
	from the training data set; the evidence from these results supports
	a regularization explanation for the effect of pre-training.},
  archiveprefix = {arXiv},
  arxivid = {arXiv:1206.5538v1},
  eprint = {arXiv:1206.5538v1},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Erhan et al._2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:pdf},
  issn = {15324435},
  keywords = {AutoEnc,GenDL,Unsupervised,deep architectures,deep belief networks,non-convex
	optimization,stacked denoising auto-encoders,unsupervised pre-training},
  mendeley-tags = {AutoEnc,GenDL,Unsupervised},
  publisher = {JMLR.org},
  url = {http://dl.acm.org/citation.cfm?id=1756006.1756025 http://portal.acm.org/citation.cfm?id=1756025}
}

@ARTICLE{Fukushima2003,
  author = {Fukushima, Kunihiko},
  title = {{Neocognitron for handwritten digit recognition}},
  journal = {Neurocomputing},
  year = {2003},
  volume = {51},
  pages = {161--180},
  month = {\#apr\#},
  abstract = {The author previously proposed a neural network model neocognitron
	for robust visual pattern recognition. This paper proposes an improved
	version of the neocognitron and demonstrates its ability using a
	large database of handwritten digits (ETL1). To improve the recognition
	rate of the neocognitron, several modifications have been applied:
	such as, the inhibitory surround in the connections from S-cells
	to C-cells, contrast-extracting layer between input and edge-extracting
	layers, self-organization of line-extracting cells, supervised competitive
	learning at the highest stage, staggered arrangement of S- and C-cells,
	and so on. These modifications allowed the removal of accessory circuits
	that were appended to the previous versions, resulting in an improvement
	of recognition rate as well as simplification of the network architecture.
	The recognition rate varies depending on the number of training patterns.
	When we used 3000 digits (300 patterns for each digit) for the learning,
	for example, the recognition rate was 98.6% for a blind test set
	(3000 digits), and 100% for the training set.},
  doi = {10.1016/S0925-2312(02)00614-8},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_2003_Neocognitron for handwritten digit recognition.pdf:pdf},
  issn = {09252312},
  keywords = {Handwritten digit,Multi-layered network,Neocognitron,Neural network
	model,Visual pattern recognition},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231202006148}
}

@ARTICLE{Fukushima1980,
  author = {Fukushima, Kunihiko},
  title = {{Neocognitron: A self-organizing neural network model for a mechanism
	of pattern recognition unaffected by shift in position}},
  journal = {Biol. Cybern.},
  year = {1980},
  volume = {36},
  pages = {193--202},
  number = {4},
  month = {\#apr\#},
  doi = {10.1007/BF00344251},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_1980_Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in positio.pdf:pdf},
  issn = {0340-1200},
  url = {http://link.springer.com/10.1007/BF00344251}
}

@ARTICLE{G.E.Hinton,
  author = {{G. E. Hinton, A. Krizhevsky}, S. D. Wang},
  title = {{Transforming Auto-encoders}},
  journal = {Artif. Neural Networks Mach. Learn. 2011.},
  year = {2011},
  pages = {44--51.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/G. E. Hinton, A. Krizhevsky_2011_Transforming Auto-encoders.pdf:pdf},
  keywords = {Vision},
  mendeley-tags = {Vision},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.220.5099}
}

@ARTICLE{Garcia2002,
  author = {Garcia, C and Delakis, M},
  title = {{A neural architecture for fast and robust face detection}},
  journal = {Pattern Recognition, 2002. Proceedings. 16th Int. Conf.},
  year = {2002},
  volume = {2},
  pages = {44 -- 47 vol.2},
  number = {11},
  abstract = { In this paper, we present a connectionist approach for detecting
	and precisely localizing semi-frontal human faces in complex images,
	making no assumption about the content or the lighting conditions
	of the scene, or about the size or the appearance of the faces. We
	propose a convolutional neural network architecture designed to recognize
	strongly variable face patterns directly from pixel images with no
	preprocessing, by automatically synthesizing its own set of feature
	extractors from a large training set of faces. We present in details
	the optimized design of our architecture, our learning strategy and
	the resulting process of face detection. We also provide experimental
	results to demonstrate the robustness of our approach and its capability
	to precisely detect extremely variable faces in uncontrolled environments.},
  doi = {10.1109/ICPR.2002.1048232},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Garcia, Delakis_2002_A neural architecture for fast and robust face detection.pdf:pdf},
  issn = {1051-4651},
  keywords = {automatic synthesis; complex images; connectionist}
}

@ARTICLE{Hinton2006a,
  author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  title = {{A fast learning algorithm for deep belief nets.}},
  journal = {Neural Comput.},
  year = {2006},
  volume = {18},
  pages = {1527--54},
  number = {7},
  month = {\#jul\#},
  abstract = {We show how to use "complementary priors" to eliminate the explaining-away
	effects that make inference difficult in densely connected belief
	nets that have many hidden layers. Using complementary priors, we
	derive a fast, greedy algorithm that can learn deep, directed belief
	networks one layer at a time, provided the top two layers form an
	undirected associative memory. The fast, greedy algorithm is used
	to initialize a slower learning procedure that fine-tunes the weights
	using a contrastive version of the wake-sleep algorithm. After fine-tuning,
	a network with three hidden layers forms a very good generative model
	of the joint distribution of handwritten digit images and their labels.
	This generative model gives better digit classification than the
	best discriminative learning algorithms. The low-dimensional manifolds
	on which the digits lie are modeled by long ravines in the free-energy
	landscape of the top-level associative memory, and it is easy to
	explore these ravines by using the directed connections to display
	what the associative memory has in mind.},
  doi = {10.1162/neco.2006.18.7.1527},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Osindero, Teh_2006_A fast learning algorithm for deep belief nets.pdf:pdf},
  issn = {0899-7667},
  keywords = {Algorithms,Animals,DBN,Humans,Learning,Learning: physiology,Neural
	Networks (Computer),Neurons,Neurons: physiology},
  mendeley-tags = {DBN},
  pmid = {16764513},
  shorttitle = {Neural Computation},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513}
}

@ARTICLE{Hinton2006,
  author = {Hinton, G E and Salakhutdinov, R R},
  title = {{Reducing the dimensionality of data with neural networks.}},
  journal = {Science},
  year = {2006},
  volume = {313},
  pages = {504--507},
  number = {5786},
  month = {\#jul\#},
  abstract = {High-dimensional data can be converted to low-dimensional codes by
	training a multilayer neural network with a small central layer to
	reconstruct high-dimensional input vectors. Gradient descent can
	be used for fine-tuning the weights in such "autoencoder" networks,
	but this works well only if the initial weights are close to a good
	solution. We describe an effective way of initializing the weights
	that allows deep autoencoder networks to learn low-dimensional codes
	that work much better than principal components analysis as a tool
	to reduce the dimensionality of data.},
  doi = {10.1126/science.1127647},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Salakhutdinov_2006_Reducing the dimensionality of data with neural networks.pdf:pdf},
  isbn = {3135786504},
  issn = {0036-8075},
  pmid = {16873662},
  url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746600649&partnerID=tZOtx3y1}
}

@ARTICLE{Ji2013,
  author = {Ji, Shuiwang and Yang, Ming and Yu, Kai},
  title = {{3D convolutional neural networks for human action recognition.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2013},
  volume = {35},
  pages = {221--31},
  number = {1},
  month = {\#jan\#},
  abstract = {We consider the automated recognition of human actions in surveillance
	videos. Most current methods build classifiers based on complex handcrafted
	features computed from the raw inputs. Convolutional neural networks
	(CNNs) are a type of deep model that can act directly on the raw
	inputs. However, such models are currently limited to handling 2D
	inputs. In this paper, we develop a novel 3D CNN model for action
	recognition. This model extracts features from both the spatial and
	the temporal dimensions by performing 3D convolutions, thereby capturing
	the motion information encoded in multiple adjacent frames. The developed
	model generates multiple channels of information from the input frames,
	and the final feature representation combines information from all
	channels. To further boost the performance, we propose regularizing
	the outputs with high-level features and combining the predictions
	of a variety of different models. We apply the developed models to
	recognize human actions in the real-world environment of airport
	surveillance videos, and they achieve superior performance in comparison
	to baseline methods.},
  doi = {10.1109/TPAMI.2012.59},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ji, Yang, Yu_2013_3D convolutional neural networks for human action recognition.pdf:pdf},
  issn = {1939-3539},
  keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted:
	methods,Decision Support Techniques,Image Interpretation,Imaging,Movement,Movement:
	physiology,Neural Networks (Computer),Pattern Recognition,Subtraction
	Technique,Three-Dimensional,Three-Dimensional: methods},
  pmid = {22392705},
  shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/22392705}
}

@INPROCEEDINGS{Krizhevsky2012,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2012},
  pages = {1097--1105},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
  keywords = {CNN},
  mendeley-tags = {CNN},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional}
}

@ARTICLE{Lawrence1997,
  author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
  title = {{Face recognition: a convolutional neural-network approach.}},
  journal = {IEEE Trans. Neural Netw.},
  year = {1997},
  volume = {8},
  pages = {98--113},
  number = {1},
  month = {\#jan\#},
  abstract = {We present a hybrid neural-network for human face recognition which
	compares favourably with other methods. The system combines local
	image sampling, a self-organizing map (SOM) neural network, and a
	convolutional neural network. The SOM provides a quantization of
	the image samples into a topological space where inputs that are
	nearby in the original space are also nearby in the output space,
	thereby providing dimensionality reduction and invariance to minor
	changes in the image sample, and the convolutional neural network
	provides partial invariance to translation, rotation, scale, and
	deformation. The convolutional network extracts successively larger
	features in a hierarchical set of layers. We present results using
	the Karhunen-Loeve transform in place of the SOM, and a multilayer
	perceptron (MLP) in place of the convolutional network for comparison.
	We use a database of 400 images of 40 individuals which contains
	quite a high degree of variability in expression, pose, and facial
	details. We analyze the computational complexity and discuss how
	new classes could be added to the trained recognizer.},
  doi = {10.1109/72.554195},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lawrence et al._1997_Face recognition a convolutional neural-network approach.pdf:pdf},
  issn = {1045-9227},
  keywords = {CNN,Face recognition,Feature extraction,Humans,Image databases,Image
	sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural
	networks,Quantization,Spatial databases,computational complexity,convolution,convolutional
	neural-network,dimensionality reduction,face recognition,feature
	extraction,image matching,invariance,local image sampling,quantisation
	(signal),quantization,self-organising feature maps,self-organizing
	map,template matching,topological space,topology},
  mendeley-tags = {CNN},
  pmid = {18255614},
  shorttitle = {Neural Networks, IEEE Transactions on},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614}
}

@ARTICLE{LeCun1990,
  author = {{LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard},
	L. D. Jackel},
  title = {{Handwritten Digit Recognition with a Back-Propagation Network}},
  journal = {Adv. Neural Inf. Process. Syst.},
  year = {1990},
  pages = {396--404},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard_1990_Handwritten Digit Recognition with a Back-Propagation Network.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076}
}

@ARTICLE{LeCun1998a,
  author = {LeCun, Yann and Bengio, Yoshua},
  title = {{Convolutional networks for images, speech, and time series}},
  year = {1998},
  pages = {255--258},
  month = {\#oct\#},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, Bengio_1998_Convolutional networks for images, speech, and time series.pdf:pdf},
  isbn = {0-262-51102-9},
  publisher = {MIT Press},
  url = {http://dl.acm.org/citation.cfm?id=303568.303704}
}

@ARTICLE{LeCun1989,
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard,
	R. E. and Hubbard, W. and Jackel, L. D.},
  title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
  journal = {Neural Comput.},
  year = {1989},
  volume = {1},
  pages = {541--551},
  number = {4},
  month = {\#dec\#},
  abstract = {The ability of learning networks to generalize can be greatly enhanced
	by providing constraints from the task domain. This paper demonstrates
	how such constraints can be integrated into a backpropagation network
	through the architecture of the network. This approach has been successfully
	applied to the recognition of handwritten zip code digits provided
	by the U.S. Postal Service. A single network learns the entire recognition
	operation, going from the normalized image of the character to the
	final classification.},
  doi = {10.1162/neco.1989.1.4.541},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1989_Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
  issn = {0899-7667},
  keywords = {CNN},
  language = {en},
  mendeley-tags = {CNN},
  publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541#.VOiy7DTkdNo}
}

@ARTICLE{LeCun1998,
  author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  title = {{Gradient-based learning applied to document recognition}},
  journal = {Proc. IEEE},
  year = {1998},
  volume = {86},
  pages = {2278--2324},
  number = {11},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm
	constitute the best example of a successful gradient based learning
	technique. Given an appropriate network architecture, gradient-based
	learning algorithms can be used to synthesize a complex decision
	surface that can classify high-dimensional patterns, such as handwritten
	characters, with minimal preprocessing. This paper reviews various
	methods applied to handwritten character recognition and compares
	them on a standard handwritten digit recognition task. Convolutional
	neural networks, which are specifically designed to deal with the
	variability of 2D shapes, are shown to outperform all other techniques.
	Real-life document recognition systems are composed of multiple modules
	including field extraction, segmentation recognition, and language
	modeling. A new learning paradigm, called graph transformer networks
	(GTN), allows such multimodule systems to be trained globally using
	gradient-based methods so as to minimize an overall performance measure.
	Two systems for online handwriting recognition are described. Experiments
	demonstrate the advantage of global training, and the flexibility
	of graph transformer networks. A graph transformer network for reading
	a bank cheque is also described. It uses convolutional neural network
	character recognizers combined with global training techniques to
	provide record accuracy on business and personal cheques. It is deployed
	commercially and reads several million cheques per day},
  doi = {10.1109/5.726791},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1998_Gradient-based learning applied to document recognition.pdf:pdf},
  issn = {00189219},
  keywords = {2D shape variability,Character recognition,Feature extraction,GTN,Hidden
	Markov models,Machine learning,Multi-layer neural network,Neural
	networks,Optical character recognition software,Optical computing,Pattern
	recognition,Principal component analysis,back-propagation,backpropagation,cheque
	reading,complex decision surface synthesis,convolution,convolutional
	neural network character recognizers,document recognition,document
	recognition systems,field extraction,gradient based learning technique,gradient-based
	learning,graph transformer networks,handwritten character recognition,handwritten
	digit recognition task,high-dimensional patterns,language modeling,multilayer
	neural networks,multilayer perceptrons,multimodule systems,optical
	character recognition,performance measure minimization,segmentation
	recognition},
  shorttitle = {Proceedings of the IEEE},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=726791}
}

@INPROCEEDINGS{Lee2009b,
  author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew
	Y.},
  title = {{Convolutional deep belief networks for scalable unsupervised learning
	of hierarchical representations}},
  booktitle = {Proc. 26th Annu. Int. Conf. Mach. Learn. - ICML '09},
  year = {2009},
  pages = {1--8},
  address = {New York, New York, USA},
  month = {\#jun\#},
  publisher = {ACM Press},
  doi = {10.1145/1553374.1553453},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations.pdf:pdf},
  isbn = {9781605585161},
  url = {http://dl.acm.org/citation.cfm?id=1553374.1553453}
}

@INPROCEEDINGS{Lee2009,
  author = {Lee, Honglak and Pham, Peter and Largman, Yan and Ng, Andrew Y.},
  title = {{Unsupervised feature learning for audio classification using convolutional
	deep belief networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2009},
  pages = {1096--1104},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised feature learning for audio classification using convolutional deep belief networks.pdf:pdf},
  keywords = {CNN,Sound,Unsupervised},
  mendeley-tags = {CNN,Sound,Unsupervised},
  url = {http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for}
}

@ARTICLE{Lehman2014,
  author = {Lehman, Joel and Clune, Jeff and Risi, Sebastian},
  title = {{An Anarchy of Methods: Current Trends in How Intelligence Is Abstracted
	in AI}},
  journal = {IEEE Intell. Syst.},
  year = {2014},
  volume = {29},
  pages = {56--62},
  number = {6},
  month = {\#nov\#},
  abstract = {Artificial intelligence (AI) is a sprawling field encompassing a diversity
	of approaches to machine intelligence and disparate perspectives
	on how intelligence should be viewed. Because researchers often engage
	only within their own specialized area of AI, there are many interesting
	broad questions about AI as a whole that often go unanswered. How
	should intelligence be abstracted in AI research? Which subfields,
	techniques, and abstractions are most promising? Why do researchers
	bet their careers on the particular abstractions and techniques of
	their chosen subfield of AI? Should AI research be "bio-inspired"
	and remain faithful to the process that produced intelligence (evolution)
	or the biological substrate that enables it (networks of neurons)?
	Discussing these big-picture questions motivated us to organize an
	AAAI Fall Symposium, which gathered participants across AI subfields
	to present and debate their views. This article distills the resulting
	insights.},
  doi = {10.1109/MIS.2014.92},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lehman, Clune, Risi_2014_An Anarchy of Methods Current Trends in How Intelligence Is Abstracted in AI.pdf:pdf},
  issn = {1541-1672},
  keywords = {AI,AI abstraction,AI research,AI subfields,AI techniques,Adaptive
	systems,Artificial intelligence,Biological system modeling,Brain
	modeling,Computational modeling,Design methodology,Neural networks,Neuroscience,Robots,adaptive
	systems,artificial intelligence,bio-inspired research,cognitive science,computational
	neuroscience,deep learning,design automation,developmental robotics,evolving
	neural networks,intelligent systems,machine intelligence,neuroevolution},
  shorttitle = {Intelligent Systems, IEEE},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6982117}
}

@ARTICLE{Marinai2005,
  author = {Marinai, Simone and Gori, Marco and Soda, Giovanni and Society, Computer},
  title = {{Artificial neural networks for document analysis and recognition.}},
  journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year = {2005},
  volume = {27},
  pages = {23--35},
  number = {1},
  month = {\#jan\#},
  abstract = {Artificial neural networks have been extensively applied to document
	analysis and recognition. Most efforts have been devoted to the recognition
	of isolated handwritten and printed characters with widely recognized
	successful results. However, many other document processing tasks,
	like preprocessing, layout analysis, character segmentation, word
	recognition, and signature verification, have been effectively faced
	with very promising results. This paper surveys the most significant
	problems in the area of offline document image processing, where
	connectionist-based approaches have been applied. Similarities and
	differences between approaches belonging to different categories
	are discussed. A particular emphasis is given on the crucial role
	of prior knowledge for the conception of both appropriate architectures
	and learning algorithms. Finally, the paper provides a critical analysis
	on the reviewed approaches and depicts the most promising research
	guidelines in the field. In particular, a second generation of connectionist-based
	models are foreseen which are based on appropriate graphical representations
	of the learning environment.},
  doi = {10.1109/TPAMI.2005.4},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Marinai et al._2005_Artificial neural networks for document analysis and recognition.pdf:pdf},
  issn = {0162-8828},
  keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Automatic
	Data Processing,Automatic Data Processing: methods,Computer Graphics,Computer-Assisted,Computer-Assisted:
	methods,Documentation,Handwriting,Image Enhancement,Image Enhancement:
	methods,Image Interpretation,Information Storage and Retrieval,Information
	Storage and Retrieval: methods,Neural Networks (Computer),Numerical
	Analysis,Pattern Recognition,Reading,Reproducibility of Results,Sensitivity
	and Specificity,Signal Processing,User-Computer Interface},
  pmid = {15628266},
  shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/15628266}
}

@ARTICLE{Mohamed2012,
  author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
  title = {{Acoustic Modeling Using Deep Belief Networks}},
  journal = {IEEE Trans. Audio. Speech. Lang. Processing},
  year = {2012},
  volume = {20},
  pages = {14--22},
  number = {1},
  month = {\#jan\#},
  abstract = {Gaussian mixture models are currently the dominant technique for modeling
	the emission distribution of hidden Markov models for speech recognition.
	We show that better phone recognition on the TIMIT dataset can be
	achieved by replacing Gaussian mixture models by deep neural networks
	that contain many layers of features and a very large number of parameters.
	These networks are first pre-trained as a multi-layer generative
	model of a window of spectral feature vectors without making use
	of any discriminative information. Once the generative pre-training
	has designed the features, we perform discriminative fine-tuning
	using backpropagation to adjust the features slightly to make them
	better at predicting a probability distribution over the states of
	monophone hidden Markov models.},
  doi = {10.1109/TASL.2011.2109382},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton_2012_Acoustic Modeling Using Deep Belief Networks.pdf:pdf},
  issn = {1558-7916},
  keywords = {Acoustic modeling,Artificial neural networks,Computational modeling,DBN,Data
	models,Gaussian mixture models,Hidden Markov models,Speech,Speech
	recognition,TIMIT dataset,Training,acoustic modeling,backpropagation,belief
	networks,deep belief networks (DBNs),discriminative fine-tuning,emission
	distribution,hidden Markov models,monophone hidden Markov models,multilayer
	generative model,neural nets,neural networks,phone recognition,probability
	distribution,spectral feature vectors,speech recognition,statistical
	distributions},
  mendeley-tags = {DBN},
  shorttitle = {Audio, Speech, and Language Processing, IEEE Trans},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5704567}
}

@INPROCEEDINGS{Ngiam2011,
  author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and
	Lee, Honglak and Ng, Andrew Y},
  title = {{Multimodal Deep Learning}},
  booktitle = {Proc. 28th Int. Conf. Mach. Learn.},
  year = {2011},
  pages = {689--696},
  abstract = {Deep networks have been successfully applied to unsupervised feature
	learning for single modalities (e.g., text, images or audio). In
	this work, we propose a novel application of deep networks to learn
	features over multiple modalities. We present a series of tasks for
	multimodal learning and show how to train deep networks that learn
	features to address these tasks. In particular, we demonstrate cross
	modality feature learning, where better features for one modality
	(e.g., video) can be learned ifmultiple modalities (e.g., audio and
	video) are present at feature learning time. Furthermore, we show
	how to learn a shared representation between modalities and evalu-
	ate it on a unique task, where the classifier is trained with audio-only
	data but tested with video-only data and vice-versa. Our mod- els
	are validated on the CUAVE and AVLet- ters datasets on audio-visual
	speech classifi- cation, demonstrating best published visual speech
	classification on AVLetters and effec- tive shared representation
	learning.},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ngiam et al._2011_Multimodal Deep Learning.pdf:pdf}
}

@ARTICLE{QuocV.Le,
  author = {{Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado,
	Jeff Dean}, Andrew Y. Ng},
  title = {{Building high-level features using large scale unsupervised learning}},
  journal = {Int. Conf. Mach. Learn.},
  year = {2012},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean_2012_Building high-level features using large scale unsupe.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.261.605}
}

@INPROCEEDINGS{Ranzato2008,
  author = {Ranzato, Marc'aurelio and Boureau, Y-lan and Cun, Yann L.},
  title = {{Sparse Feature Learning for Deep Belief Networks}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2008},
  pages = {1185--1192},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato, Boureau, Cun_2008_Sparse Feature Learning for Deep Belief Networks.pdf:pdf},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://papers.nips.cc/paper/3363-sparse-feature-learning-for-deep-belief-networks}
}

@ARTICLE{Salakhutdinov2009a,
  author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
  title = {{Semantic hashing}},
  journal = {Int. J. Approx. Reason.},
  year = {2009},
  volume = {50},
  pages = {969--978},
  number = {7},
  month = {\#jul\#},
  abstract = {We show how to learn a deep graphical model of the word-count vectors
	obtained from a large set of documents. The values of the latent
	variables in the deepest layer are easy to infer and give a much
	better representation of each document than Latent Semantic Analysis.
	When the deepest layer is forced to use a small number of binary
	variables (e.g. 32), the graphical model performs �?semantic hashing�?:
	Documents are mapped to memory addresses in such a way that semantically
	similar documents are located at nearby addresses. Documents similar
	to a query document can then be found by simply accessing all the
	addresses that differ by only a few bits from the address of the
	query document. This way of extending the efficiency of hash-coding
	to approximate matching is much faster than locality sensitive hashing,
	which is the fastest current method. By using semantic hashing to
	filter the documents given to TF-IDF, we achieve higher accuracy
	than applying TF-IDF to the entire document set.},
  doi = {10.1016/j.ijar.2008.11.006},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Hinton_2009_Semantic hashing.pdf:pdf},
  issn = {0888613X},
  keywords = {Graphical models,Information retrieval,Unsupervised learning},
  url = {http://www.sciencedirect.com/science/article/pii/S0888613X08001813}
}

@INPROCEEDINGS{Salakhutdinov2007a,
  author = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
  title = {{Restricted Boltzmann machines for collaborative filtering}},
  booktitle = {Proc. 24th Int. Conf. Mach. Learn. - ICML '07},
  year = {2007},
  pages = {791--798},
  address = {New York, New York, USA},
  month = {\#jun\#},
  publisher = {ACM Press},
  doi = {10.1145/1273496.1273596},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Mnih, Hinton_2007_Restricted Boltzmann machines for collaborative filtering.pdf:pdf},
  isbn = {9781595937933},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://dl.acm.org/citation.cfm?id=1273496.1273596}
}

@ARTICLE{Schmidhuber2014,
  author = {Schmidhuber, Juergen},
  title = {{Deep Learning in Neural Networks: An Overview}},
  year = {2014},
  pages = {75},
  month = {\#apr\#},
  abstract = {In recent years, deep artificial neural networks (including recurrent
	ones) have won numerous contests in pattern recognition and machine
	learning. This historical survey compactly summarises relevant work,
	much of it from the previous millennium. Shallow and deep learners
	are distinguished by the depth of their credit assignment paths,
	which are chains of possibly learnable, causal links between actions
	and effects. I review deep supervised learning (also recapitulating
	the history of backpropagation), unsupervised learning, reinforcement
	learning & evolutionary computation, and indirect search for short
	programs encoding deep and large networks.},
  archiveprefix = {arXiv},
  arxivid = {1404.7828},
  eprint = {1404.7828},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Schmidhuber_2014_Deep Learning in Neural Networks An Overview.pdf:pdf},
  url = {http://arxiv.org/abs/1404.7828}
}

@INPROCEEDINGS{Simard2003,
  author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
  title = {{Best practices for convolutional neural networks applied to visual
	document analysis}},
  booktitle = {Seventh Int. Conf. Doc. Anal. Recognition, 2003. Proceedings.},
  year = {2003},
  volume = {1},
  pages = {958--963},
  publisher = {IEEE Comput. Soc},
  abstract = {Not Available},
  doi = {10.1109/ICDAR.2003.1227801},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Simard, Steinkraus, Platt_2003_Best practices for convolutional neural networks applied to visual document analysis.pdf:pdf},
  isbn = {0-7695-1960-1},
  keywords = {Best practices,CNN,Concrete,Convolution,Handwriting recognition,Industrial
	training,Information processing,Neural networks,Performance analysis,Support
	vector machines,Text analysis},
  mendeley-tags = {CNN},
  shorttitle = {Document Analysis and Recognition, 2003. Proceedin},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801}
}

@ARTICLE{Srivastava2014,
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and
	Sutskever, Ilya and Salakhutdinov, Ruslan},
  title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
  journal = {J. Mach. Learn. Res.},
  year = {2014},
  volume = {15},
  pages = {1929--1958},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava et al._2014_Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
  url = {http://jmlr.org/papers/v15/srivastava14a.html}
}

@INPROCEEDINGS{Srivastava2012,
  author = {Srivastava, Nitish and Salakhutdinov, Ruslan R.},
  title = {{Multimodal Learning with Deep Boltzmann Machines}},
  booktitle = {Adv. Neural Inf. Process. Syst.},
  year = {2012},
  pages = {2222--2230},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava, Salakhutdinov_2012_Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines}
}

@ARTICLE{Vincent2010,
  author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio,
	Yoshua and Manzagol, Pierre-Antoine},
  title = {{Stacked Denoising Autoencoders: Learning Useful Representations
	in a Deep Network with a Local Denoising Criterion}},
  journal = {J. Mach. Learn. Res.},
  year = {2010},
  volume = {11},
  pages = {3371--3408},
  month = {\#mar\#},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2010_Stacked Denoising Autoencoders Learning Useful Representations in a Deep Network with a Local Denoising Criterion.pdf:pdf},
  issn = {1532-4435},
  publisher = {JMLR.org},
  url = {http://dl.acm.org/citation.cfm?id=1756006.1953039}
}

@ARTICLE{Lecun1995,
  author = {{Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes,
	John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard},
	Vladimir Vapnik},
  title = {{Learning Algorithms For Classification: A Comparison On Handwritten
	Digit Recognition}},
  journal = {Neural Networks Stat. Mech. Perspect.},
  year = {1995},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes, John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard_1.pdf:pdf},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.4628}
}

@ARTICLE{YoshuaBengio,
  author = {{Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e}
	De Montr\'{e}al}, Montr\'{e}al Qu\'{e}bec},
  title = {{Greedy layer-wise training of deep networks}},
  journal = {Adv. Neural Inf. Process. Syst.},
  year = {2007},
  pages = {153},
  number = {19},
  file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\\'{e} De Montr\\'{e}al_2007_Greedy layer-wise training of deep networks.pdf:pdf},
  keywords = {DBN},
  mendeley-tags = {DBN},
  url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.2022}
}

