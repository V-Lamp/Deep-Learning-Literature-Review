Automatically generated by Mendeley Desktop 1.13.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Lee2011,
abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
address = {New York, New York, USA},
author = {Lee, Honglak and Grosse, Roger B and Ranganath, Rajesh and Ng, Andrew Y.},
booktitle = {Communications of the ACM},
doi = {10.1145/2001269.2001295},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised learning of hierarchical representations with convolutional deep belief networks.pdf:pdf},
isbn = {9781605585161},
issn = {00010782},
month = jun,
number = {10},
pages = {95--103},
publisher = {ACM Press},
title = {{Unsupervised learning of hierarchical representations with convolutional deep belief networks}},
url = {http://dl.acm.org/citation.cfm?id=1553374.1553453 http://www.scopus.com/inward/record.url?eid=2-s2.0-80053540444&partnerID=tZOtx3y1 http://www.scopus.com/inward/record.url?eid=2-s2.0-71149119164&partnerID=tZOtx3y1},
volume = {54},
year = {2009}
}
@article{Vincent2010a,
abstract = {We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations. © 2010.},
author = {Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine Antoine},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2010_Stacked Denoising Autoencoders Learning Useful Representations in a Deep Network with a Local Denoising Criterion.pdf:pdf},
issn = {15324435},
journal = {The Journal of Machine Learning Research},
keywords = {Autoencoders,Deep belief networks,Deep learning,Denoising,Unsupervised feature learning},
month = mar,
pages = {3371--3408},
publisher = {JMLR.org},
title = {{Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1953039 http://www.scopus.com/inward/record.url?eid=2-s2.0-79551480483&partnerID=tZOtx3y1},
volume = {11},
year = {2010}
}
@inproceedings{Bengio2007a,
abstract = {Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization.},
author = {{Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e} De Montr\'{e}al}, Montr\'{e}al Qu\'{e}bec and Bengio, Yoshua and Lamblin, Pascal and Popovici, Dan and Larochelle, Hugo},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yoshua Bengio, Pascal Lamblin, Dan Popovici, Hugo Larochelle, Universit\'{e} De Montr\'{e}al et al._2007_Greedy layer-wise training of deep netw.pdf:pdf},
isbn = {9780262195683},
issn = {10495258},
keywords = {DBN},
mendeley-tags = {DBN},
number = {19},
pages = {153--160},
title = {{Greedy layer-wise training of deep networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84864073449&partnerID=tZOtx3y1 http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.2022},
year = {2007}
}
@article{Pradhan2005,
abstract = {The natural language processing community has recently experienced a growth of interest in domain independent shallow semantic parsing-the process of assigning a Who did What to Whom, When, Where, Why, How etc. structure to plain text. This process entails identifying groups of words in a sentence that represent these semantic arguments and assigning specific labels to them. It could play a key role in NLP tasks like Information Extraction, Question Answering and Summarization. We propose a machine learning algorithm for semantic role parsing, extending the work of Gildea and Jurafsky (2002), Surdeanu et al. (2003) and others. Our algorithm is based on Support Vector Machines which we show give large improvement in performance over earlier classifiers. We show performance improvements through a number of new features designed to improve generalization to unseen data, such as automatic clustering of verbs. We also report on various analytic studies examining which features are most important, comparing our classifier to other machine learning algorithms in the literature, and testing its generalization to new test set from different genre. On the task of assigning semantic labels to the PropBank (Kingsbury, Palmer, & Marcus, 2002) corpus, our final system has a precision of 84% and a recall of 75%, which are the best results currently reported for this task. Finally, we explore a completely different architecture which does not requires a deep syntactic parse. We reformulate the task as a combined chunking and classification problem, thus allowing our algorithm to be applied to new languages or genres of text for which statistical syntactic parsers may not be available.},
author = {Pradhan, Sameer and Hacioglu, Kadri and Krugler, Valerie and Ward, Wayne and Martin, James H. and Jurafsky, Daniel},
doi = {10.1007/s10994-005-0912-2},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Shallow semantic parsing,Support vector machines},
month = jun,
number = {1-3},
pages = {11--39},
title = {{Support Vector Learning for Semantic Argument Classification}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-24044446171&partnerID=tZOtx3y1},
volume = {60},
year = {2005}
}
@inproceedings{Viaud2008,
abstract = {With the increase of online resources, one main challenge for multimedia content providers is to provide efficient and user friendly tools for a deep and shallow navigation adapted to large scale audiovisual content. This paper describes a generic framework to build visual interactive applications the objectives of which are to enhance the understanding and to allow easy access to multimedia resources and management. Visual Maps are built on multi-modal similarity matrices computed from automatically extracted descriptors and use graph clustering and layout methods. Active relevance feedback methods are applied to allow users to control the maps evolution according to their needs. The First results of users' evaluation are presented for one of our tools. Copyright 2008 ACM.},
address = {New York, New York, USA},
author = {Viaud, Marie-Luce and Thi\`{e}vre, J\'{e}r\"{o}me and Go\"{e}au, Herv\'{e} and Saulnier, Agnes and Buisson, Olivier},
booktitle = {Proceedings of the 2008 international conference on Content-based image and video retrieval - CIVR '08},
doi = {10.1145/1386352.1386440},
isbn = {9781605580708},
keywords = {Active learning,Cross modal descriptors,Index structuring,Information visualization,Interactivity,Multimedia archives,Scalability},
pages = {609},
publisher = {ACM Press},
title = {{Interactive components for visual exploration of multimedia archives}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57549087246&partnerID=tZOtx3y1},
year = {2008}
}
@article{Mikolov2013,
author = {Mikolov, T and Yih, W and Zweig, G},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Mikolov, Yih, Zweig_2013_Linguistic Regularities in Continuous Space Word Representations.pdf:pdf},
journal = {HLT-NAACL},
pages = {746--751},
title = {{Linguistic Regularities in Continuous Space Word Representations.}},
url = {http://www.aclweb.org/anthology/N13-1#page=784},
year = {2013}
}
@article{Salakhutdinov2009a,
abstract = {We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs "semantic hashing": Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set. © 2008 Elsevier Inc. All rights reserved.},
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
doi = {10.1016/j.ijar.2008.11.006},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Hinton_2009_Semantic hashing.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {Graphical models,Information retrieval,Unsupervised learning},
month = jul,
number = {7},
pages = {969--978},
title = {{Semantic hashing}},
url = {http://www.sciencedirect.com/science/article/pii/S0888613X08001813 http://www.scopus.com/inward/record.url?eid=2-s2.0-67449128732&partnerID=tZOtx3y1},
volume = {50},
year = {2009}
}
@inproceedings{Larochelle2008,
abstract = {Recently, many applications for Restricted Boltzmann Machines (RBMs) have been developed for a large variety of learning problems. However, RBMs are usually used as feature extractors for another learning algorithm or to provide a good initialization for deep feed-forward neural network classifiers, and are not considered as a stand-alone solution to classification problems. In this paper, we argue that RBMs provide a self-contained framework for deriving competitive non-linear classifiers. We present an evaluation of different learning algorithms for RBMs which aim at introducing a discriminative component to RBM training and improve their performance as classifiers. This approach is simple in that RBMs are used directly to build a classifier, rather than as a stepping stone. Finally, we demonstrate how discriminative RBMs can also be successfully employed in a semi-supervised setting. Copyright 2008 by the author(s)/owner(s).},
author = {Larochelle, Hugo and Bengio, Yoshua},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Larochelle, Bengio_2008_Classification using discriminative restricted boltzmann machines.pdf:pdf},
isbn = {9781605582054},
pages = {536--543},
title = {{Classification using discriminative restricted boltzmann machines}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449110012&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{Goodfellow2009,
abstract = {For many pattern recognition tasks, the ideal input feature would be invariant to multiple confounding properties (such as illumination and viewing angle, in computer vision applications). Recently, deep architectures trained in an unsupervised manner have been proposed as an automatic method for extracting useful features. However, it is difficult to evaluate the learned features by any means other than using them in a classifier. In this paper, we propose a number of empirical tests that directly measure the degree to which these learned features are invariant to different input transformations. We find that stacked autoencoders learn modestly increasingly invariant features with depth when trained on natural images. We find that convolutional deep belief networks learn substantially more invariant features in each layer. These results further justify the use of "deep" vs. "shallower" representations, but suggest that mechanisms beyond merely stacking one autoencoder on top of another may be important for achieving invariance. Our evaluation metrics can also be used to evaluate future work in deep learning, and thus help the development of future algorithms.},
author = {Goodfellow, Ian J. and Le, Quoc V. and Saxe, Andrew M. and Lee, Honglak and Ng, Andrew Y.},
booktitle = {Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference},
isbn = {9781615679119},
pages = {646--654},
title = {{Measuring invariances in deep networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84860644702&partnerID=tZOtx3y1},
year = {2009}
}
@inproceedings{Martens2010,
abstract = {We develop a 2
                        nd-order optimization method based on the "Hessian-free" approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn't limited in applicability to auto-encoders, or any specific model class. We also discuss the issue of "pathological curvature" as a possible explanation for the difficulty of deep-learning and how 2
                        nd-order optimization, and our method in particular, effectively deals with it. Copyright 2010 by the author(s)/owner(s).},
author = {Martens, James},
booktitle = {ICML 2010 - Proceedings, 27th International Conference on Machine Learning},
isbn = {9781605589077},
pages = {735--742},
title = {{Deep learning via Hessian-free optimization}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956541496&partnerID=tZOtx3y1},
year = {2010}
}
@inproceedings{Ciresan2012,
abstract = {Traditional methods of computer vision and machine learning cannot match human performance on tasks such as the recognition of handwritten digits or traffic signs. Our biologically plausible, wide and deep artificial neural network architectures can. Small (often minimal) receptive fields of convolutional winner-take-all neurons yield large network depth, resulting in roughly as many sparsely connected neural layers as found in mammals between retina and visual cortex. Only winner neurons are trained. Several deep neural columns become experts on inputs preprocessed in different ways; their predictions are averaged. Graphics cards allow for fast training. On the very competitive MNIST handwriting benchmark, our method is the first to achieve near-human performance. On a traffic sign recognition benchmark it outperforms humans by a factor of two. We also improve the state-of-the-art on a plethora of common image classification benchmarks. © 2012 IEEE.},
author = {Ciresan, D. and Meier, U. and Schmidhuber, J.},
booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2012.6248110},
isbn = {978-1-4673-1228-8},
issn = {10636919},
month = jun,
pages = {3642--3649},
publisher = {IEEE},
title = {{Multi-column deep neural networks for image classification}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866714584&partnerID=tZOtx3y1},
year = {2012}
}
@inproceedings{Salakhutdinov2008,
abstract = {Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data. Copyright 2008 by the author(s)/owner(s).},
author = {Salakhutdinov, Ruslan and Murray, Iain},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Murray_2008_On the quantitative analysis of deep belief networks.pdf:pdf},
isbn = {9781605582054},
pages = {872--879},
title = {{On the quantitative analysis of deep belief networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449102578&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{Lee2009a,
abstract = {In recent years, deep learning approaches have gained significant interest as a way of building hierarchical representations from unlabeled data. However, to our knowledge, these deep learning approaches have not been extensively studied for auditory data. In this paper, we apply convolutional deep belief networks to audio data and empirically evaluate them on various audio classification tasks. In the case of speech data, we show that the learned features correspond to phones/phonemes. In addition, our feature representations learned from unlabeled audio data show very good performance for multiple audio classification tasks. We hope that this paper will inspire more research on deep learning approaches applied to a wide range of audio recognition tasks.},
author = {Lee, Honglak and Yan, Largman and Pham, Peter and Ng, Andrew Y. A.Y. and Largman, Yan and Ng, Andrew Y. A.Y. and Pham, Peter and Ng, Andrew Y. A.Y.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lee et al._2009_Unsupervised feature learning for audio classification using convolutional deep belief networks.pdf:pdf},
isbn = {9781615679119},
keywords = {CNN,Sound,Unsupervised},
mendeley-tags = {CNN,Sound,Unsupervised},
pages = {1096--1104},
title = {{Unsupervised feature learning for audio classification using convolutional deep belief networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956502334&partnerID=tZOtx3y1 http://papers.nips.cc/paper/3674-unsupervised-feature-learning-for http://www.scopus.com/inward/record.url?eid=2-s2.0-84863380535&partnerID=tZOtx3y1},
year = {2009}
}
@inproceedings{Hamel2010,
abstract = {Feature extraction is a crucial part of many MIR tasks. In this work, we present a system that can automatically extract relevant features from audio for a given task. The feature extraction system consists of a Deep Belief Network (DBN) on Discrete Fourier Transforms (DFTs) of the audio. We then use the activations of the trained network as inputs for a non-linear Support Vector Machine (SVM) classifier. In particular, we learned the features to solve the task of genre recognition. The learned features perform significantly better than MFCCs. Moreover, we obtain a classification accuracy of 84.3% on the Tzanetakis dataset, which compares favorably against state-of-the-art genre classifiers using frame-based features. We also applied these same features to the task of auto-tagging. The autotaggers trained with our features performed better than those that were trained with timbral and temporal features. © 2010 International Society for Music Information Retrieval.},
author = {Hamel, Philippe and Eck, Douglas},
booktitle = {Proceedings of the 11th International Society for Music Information Retrieval Conference, ISMIR 2010},
isbn = {9789039353813},
pages = {339--344},
title = {{Learning features from music audio with deep belief networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84873584268&partnerID=tZOtx3y1},
year = {2010}
}
@article{Nguyen2014,
author = {Nguyen, A and Yosinski, J and Clune, J},
journal = {arXiv preprint arXiv:1412.1897},
title = {{Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images}},
url = {http://arxiv.org/abs/1412.1897},
year = {2014}
}
@inproceedings{Srivastava2012,
author = {Srivastava, Nitish and Salakhutdinov, Ruslan R.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava, Salakhutdinov_2012_Multimodal Learning with Deep Boltzmann Machines.pdf:pdf},
keywords = {DBN},
mendeley-tags = {DBN},
pages = {2222--2230},
title = {{Multimodal Learning with Deep Boltzmann Machines}},
url = {http://papers.nips.cc/paper/4683-multimodal-learning-with-deep-boltzmann-machines},
year = {2012}
}
@misc{Deselaers,
author = {Deselaers, T. and Hasan, S. and Bender, O. and Ney, H.},
booktitle = {Proceedings of the EACL 2009Workshop on Statistical Machine Translation},
pages = {233--241},
title = {{A deep learning approach to machine transliteration}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70450166894&partnerID=tZOtx3y1}
}
@inproceedings{Boureau2010,
abstract = {Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures.},
author = {Boureau, Y-Lan and Bach, Francis and LeCun, Yann and Ponce, Jean},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539963},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boureau et al._2010_Learning mid-level features for recognition.pdf:pdf},
isbn = {978-1-4244-6984-0},
issn = {1063-6919},
keywords = {Convolutional codes,Dictionaries,Feature extraction,Gabor filter responses,Gabor filters,Image classification,Image coding,Image representation,Layout,Object recognition,SIFT descriptors,Vector quantization,coding step,feature extraction,learning (artificial intelligence),low level descriptors,mid level features learning,object recognition,pointwise transformation,pooling step,sparse coding,vector quantisation,vector quantization},
month = jun,
pages = {2559--2566},
publisher = {IEEE},
shorttitle = {Computer Vision and Pattern Recognition (CVPR), 20},
title = {{Learning mid-level features for recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5539963},
year = {2010}
}
@inproceedings{Le2011a,
abstract = {The predominant methodology in training deep learning advocates the use of stochastic gradient descent methods (SGDs). Despite its ease of implementation, SGDs are difficult to tune and parallelize. These problems make it challenging to develop, debug and scale up deep learning algorithms with SGDs. In this paper, we show that more sophisticated off-the-shelf optimization methods such as Limited memory BFGS (L-BFGS) and Conjugate gradient (CG) with line search can significantly simplify and speed up the process of pretraining deep algorithms. In our experiments, the difference between L-BFGS/CG and SGDs are more pronounced if we consider algorithmic extensions (e.g., sparsity regularization) and hardware extensions (e.g., GPUs or computer clusters). Our experiments with distributed optimization support the use of L-BFGS with locally connected networks and convolutional neural networks. Using L-BFGS, our convolutional network model achieves 0.69% on the standard MNIST dataset. This is a state-of-the-art result on MNIST among algorithms that do not use distortions or pretraining. Copyright 2011 by the author(s)/owner(s).},
author = {Le, Quoc V. and Ngiam, Jiquan and Coates, Adam and Lahiri, Abhik and Prochnow, Bobby and Ng, Andrew Y.},
booktitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
isbn = {9781450306195},
pages = {265--272},
title = {{On optimization methods for deep learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053437034&partnerID=tZOtx3y1},
year = {2011}
}
@article{Hinton2006,
abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
author = {Hinton, G E and Salakhutdinov, R R},
doi = {10.1126/science.1127647},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Salakhutdinov_2006_Reducing the dimensionality of data with neural networks.pdf:pdf},
isbn = {3135786504},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
month = jul,
number = {5786},
pages = {504--507},
pmid = {16873662},
title = {{Reducing the dimensionality of data with neural networks.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33746600649&partnerID=tZOtx3y1},
volume = {313},
year = {2006}
}
@inproceedings{Suchanek2006,
abstract = {The World Wide Web provides a nearly endless source of knowledge, which is mostly given in natural language. A first step towards exploiting this data automatically could be to extract pairs of a given semantic relation from text documents - for example all pairs of a person and her birth-date. One strategy for this task is to find text patterns that express the semantic relation, to generalize these patterns, and to apply them to a corpus to find new pairs. In this paper, we show that this approach profits significantly when deep linguistic structures are used instead of surface text patterns. We demonstrate how linguistic structures can be represented for machine learning, and we provide a theoretical analysis of the pattern matching approach. We show the benefits of our approach by extensive experiments with our prototype system LEILA. Copyright 2006 ACM.},
author = {Suchanek, Fabian M. and Ifrim, Georgiana and Weikum, Gerhard},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
isbn = {1595933395},
keywords = {Machine Learning,Pattern Matching,Relation Extraction},
pages = {712--717},
title = {{Combining linguistic and statistical analysis to extract relations from web documents}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749565187&partnerID=tZOtx3y1},
volume = {2006},
year = {2006}
}
@article{Smith2006,
abstract = {The auditory neural code must serve a wide range of auditory tasks that require great sensitivity in time and frequency and be effective over the diverse array of sounds present in natural acoustic environments. It has been suggested that sensory systems might have evolved highly efficient coding strategies to maximize the information conveyed to the brain while minimizing the required energy and neural resources. Here we show that, for natural sounds, the complete acoustic waveform can be represented efficiently with a nonlinear model based on a population spike code. In this model, idealized spikes encode the precise temporal positions and magnitudes of underlying acoustic features. We find that when the features are optimized for coding either natural sounds or speech, they show striking similarities to time-domain cochlear filter estimates, have a frequency-bandwidth dependence similar to that of auditory nerve fibres, and yield significantly greater coding efficiency than conventional signal representations. These results indicate that the auditory code might approach an information theoretic optimum and that the acoustic structure of speech might be adapted to the coding capacity of the mammalian auditory system.},
author = {Smith, Evan C and Lewicki, Michael S},
doi = {10.1038/nature04485},
issn = {1476-4687},
journal = {Nature},
keywords = {Acoustic Stimulation,Adaptation, Physiological,Adaptation, Physiological: physiology,Algorithms,Animals,Auditory Perception,Auditory Perception: physiology,Cochlea,Cochlea: physiology,Hearing,Hearing: physiology,Humans,Models, Neurological,Noise,Sensitivity and Specificity,Sound,Speech,Speech: physiology,Time Factors},
month = feb,
number = {7079},
pages = {978--82},
pmid = {16495999},
title = {{Efficient auditory coding.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33644513420&partnerID=tZOtx3y1},
volume = {439},
year = {2006}
}
@article{Mierswa2005,
abstract = {Today many private households as well as broadcasting or film companies own large collections of digital music plays. These are time series that differ from e.g. weather reports or stocks market data. The task is normally that of classification not prediction of the next value or recognizing a shape or motif. New methods for extracting features that allow to classify audio data have been developed. However the development of appropriate feature extraction methods is a tedious effort particularly because every new classification task requires tailoring the feature set anew. This paper presents a unifying framework for feature extraction from value series. Operators of this framework can be combined to feature extraction methods automatically using a genetic programming approach. The construction of features is guided by the performance of the learning classifier which uses the features. Our approach to automatic feature extraction requires a balance between the completeness of the methods on one side and the tractability of searching for appropriate methods on the other side. In this paper some theoretical considerations illustrate the trade-off. After the feature extraction a second process learns a classifier from the transformed data. The practical use of the methods is shown by two types of experiments: classification of genres and classification according to user preferences. © 2005 Springer Science + Business Media Inc.},
author = {Mierswa, Ingo and Morik, Katharina},
doi = {10.1007/s10994-005-5824-7},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Analysis of audio data,Feature extraction,Music recommender systems,Time series transformations},
month = feb,
number = {2-3},
pages = {127--149},
title = {{Automatic Feature Extraction for Classifying Audio Data}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-15544385732&partnerID=tZOtx3y1},
volume = {58},
year = {2005}
}
@misc{Kingsbury,
author = {Kingsbury, B. and Sainath, T.N. and Soltau, H.},
booktitle = {Proc. Interspeech},
title = {{Scalable minimum bayes risk training of neural network acoustic models using distributed hessian-free optimization}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84878379171&partnerID=tZOtx3y1}
}
@article{Fukushima2003,
abstract = {The author previously proposed a neural network model neocognitron for robust visual pattern recognition. This paper proposes an improved version of the neocognitron and demonstrates its ability using a large database of handwritten digits (ETL1). To improve the recognition rate of the neocognitron, several modifications have been applied: such as, the inhibitory surround in the connections from S-cells to C-cells, contrast-extracting layer between input and edge-extracting layers, self-organization of line-extracting cells, supervised competitive learning at the highest stage, staggered arrangement of S- and C-cells, and so on. These modifications allowed the removal of accessory circuits that were appended to the previous versions, resulting in an improvement of recognition rate as well as simplification of the network architecture. The recognition rate varies depending on the number of training patterns. When we used 3000 digits (300 patterns for each digit) for the learning, for example, the recognition rate was 98.6% for a blind test set (3000 digits), and 100% for the training set.},
author = {Fukushima, Kunihiko},
doi = {10.1016/S0925-2312(02)00614-8},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_2003_Neocognitron for handwritten digit recognition.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Handwritten digit,Multi-layered network,Neocognitron,Neural network model,Visual pattern recognition},
month = apr,
pages = {161--180},
title = {{Neocognitron for handwritten digit recognition}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231202006148},
volume = {51},
year = {2003}
}
@inproceedings{Devlin2014,
abstract = {decoder. We also present several varia- tions of the NNJM which provide signif- icant additive improvements. Although the model is quite simple, it yields strong empirical results. On the NIST OpenMT12 Arabic-English condi- tion, the NNJM features produce a gain of +3.0 BLEU on top of a powerful, feature- rich baseline which already includes a target-only NNLM. The NNJM features also produce a gain of +6.3 BLEU on top of a simpler baseline equivalent to Chi- ang’s (2007) original Hiero implementa- tion. Additionally, we describe two novel tech- niques for overcoming the historically high cost of using NNLM-style models in MT decoding. These techniques speed up NNJM computation by a factor of 10,000x, making the model as fast as a standard back-off LM.},
author = {Devlin, Jacob and Zbib, Rabih and Huang, Zhongqiang and Lamar, Thomas and Schwartz, Richard and Makhoul, John},
booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},
isbn = {9781937284725},
pages = {1370--1380},
title = {{Fast and Robust Neural Network Joint Models for Statistical Machine Translation}},
url = {http://acl2014.org/acl2014/P14-1/pdf/P14-1129.pdf},
year = {2014}
}
@inproceedings{Socher2011,
abstract = {We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines. \^{A}© 2011 Association for Computational Linguistics.},
author = {Socher, Richard and Pennington, Jeffrey and Huang, Eric H and Ng, Andrew Y and Manning, Christopher D},
booktitle = {EMNLP 2011 - Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference},
doi = {10.1.1.224.9432},
isbn = {978-1-937284-11-4},
pages = {151--161},
title = {{Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions}},
year = {2011}
}
@article{Hinton2006a,
abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
doi = {10.1162/neco.2006.18.7.1527},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton, Osindero, Teh_2006_A fast learning algorithm for deep belief nets.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Animals,DBN,Humans,Learning,Learning: physiology,Neural Networks (Computer),Neurons,Neurons: physiology},
mendeley-tags = {DBN},
month = jul,
number = {7},
pages = {1527--54},
pmid = {16764513},
shorttitle = {Neural Computation},
title = {{A fast learning algorithm for deep belief nets.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16764513 http://www.scopus.com/inward/record.url?eid=2-s2.0-33745805403&partnerID=tZOtx3y1},
volume = {18},
year = {2006}
}
@inproceedings{Salakhutdinov2009,
abstract = {We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are estimated using a variational approximation that tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to learn Boltzmann machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer "pre-training" phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep Boltzmann machines learn good generative models and perform well on handwritten digit and visual object recognition tasks. © 2009 by the authors.},
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
booktitle = {Journal of Machine Learning Research},
issn = {15324435},
pages = {448--455},
title = {{Deep Boltzmann machines}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84862286946&partnerID=tZOtx3y1},
volume = {5},
year = {2009}
}
@article{Fukushima1980,
author = {Fukushima, Kunihiko},
doi = {10.1007/BF00344251},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Fukushima_1980_Neocognitron A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in positio.pdf:pdf},
issn = {0340-1200},
journal = {Biological Cybernetics},
month = apr,
number = {4},
pages = {193--202},
title = {{Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position}},
url = {http://link.springer.com/10.1007/BF00344251},
volume = {36},
year = {1980}
}
@article{LeCun1990,
author = {{LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard}, L. D. Jackel},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard_1990_Handwritten Digit Recognition with a Back-Propagation Network.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
pages = {396--404},
title = {{Handwritten Digit Recognition with a Back-Propagation Network}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076},
year = {1990}
}
@article{Blei2010,
abstract = {We present the nested Chinese restaurant process (nCRP), a stochastic process that assigns probability distributions to ensembles of infinitely deep, infinitely branching trees. We show how this stochastic process can be used as a prior distribution in a Bayesian nonparametric model of document collections. Specifically, we present an application to information retrieval in which documents are modeled as paths down a random tree, and the preferential attachment dynamics of the nCRP leads to clustering of documents according to sharing of topics at multiple levels of abstraction. Given a corpus of documents, a posterior inference algorithm finds an approximation to a posterior distribution over trees, topics and allocations of words to levels of the tree. We demonstrate this algorithm on collections of scientific abstracts from several journals. This model exemplifies a recent trend in statistical machine learningthe use of Bayesian nonparametric methods to infer distributions on flexible data structures. © 2010 ACM.},
author = {Blei, David M. and Griffiths, Thomas L. and Jordan, Michael I.},
doi = {10.1145/1667053.1667056},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Bayesian nonparametric statistics,Unsupervised learning},
month = jan,
number = {2},
pages = {1--30},
title = {{The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-76849117578&partnerID=tZOtx3y1},
volume = {57},
year = {2010}
}
@article{Collobert2011,
abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
archivePrefix = {arXiv},
arxivId = {arXiv:1103.0398v1},
author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
eprint = {arXiv:1103.0398v1},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Collobert et al._2011_Natural Language Processing (almost) from Scratch.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {natural language processing,neural networks},
pages = {2493--2537},
title = {{Natural Language Processing (almost) from Scratch}},
url = {http://arxiv.org/abs/1103.0398},
volume = {12},
year = {2011}
}
@article{Yu2011,
abstract = {Today, signal processing research has a significantly widened its scope compared with just a few years ago [4], and machine learning has been an important technical area of the signal processing society. Since 2006, deep learninga new area of machine learning research has emerged [7], impacting a wide range of signal and information processing work within the traditional and the new, widened scopes. Various workshops, such as the 2009 ICML Workshop on Learning Feature Hierarchies; the 2008 NIPS Deep Learning Workshop: Foundations and Future Directions; and the 2009 NIPS Workshop on Deep Learning for Speech Recognition and Related Applications as well as an upcoming special issue on deep learning for speech and language processing in IEEE Transactions on Audio, Speech, and Language Processing (2010) have been devoted exclusively to deep learning and its applications to classical signal processing areas. We have also seen the government sponsor research on deep learning (e.g., the DARPA deep learning program, available at http://www.darpa.mil/ipto/solicit/baa/BAA-09-40- PIP.pdf). © 2010 IEEE.},
author = {Yu, Dong and Deng, Li},
doi = {10.1109/MSP.2010.939038},
issn = {1053-5888},
journal = {IEEE Signal Processing Magazine},
month = jan,
number = {1},
pages = {145--154},
title = {{Deep Learning and Its Applications to Signal and Information Processing [Exploratory DSP}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78650425762&partnerID=tZOtx3y1},
volume = {28},
year = {2011}
}
@article{Garcia2002,
abstract = { In this paper, we present a connectionist approach for detecting and precisely localizing semi-frontal human faces in complex images, making no assumption about the content or the lighting conditions of the scene, or about the size or the appearance of the faces. We propose a convolutional neural network architecture designed to recognize strongly variable face patterns directly from pixel images with no preprocessing, by automatically synthesizing its own set of feature extractors from a large training set of faces. We present in details the optimized design of our architecture, our learning strategy and the resulting process of face detection. We also provide experimental results to demonstrate the robustness of our approach and its capability to precisely detect extremely variable faces in uncontrolled environments.},
author = {Garcia, C and Delakis, M},
doi = {10.1109/ICPR.2002.1048232},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Garcia, Delakis_2002_A neural architecture for fast and robust face detection.pdf:pdf},
issn = {1051-4651},
journal = {Pattern Recognition, 2002. Proceedings. 16th International Conference on},
keywords = {automatic synthesis; complex images; connectionist},
number = {11},
pages = {44 -- 47 vol.2},
title = {{A neural architecture for fast and robust face detection}},
volume = {2},
year = {2002}
}
@article{Erman2007,
abstract = {Identifying and categorizing network traffic by application type is challenging because of the continued evolution of applications, especially of those with a desire to be undetectable. The diminished effectiveness of port-based identification and the overheads of deep packet inspection approaches motivate us to classify traffic by exploiting distinctive flow characteristics of applications when they communicate on a network. In this paper, we explore this latter approach and propose a semi-supervised classification method that can accommodate both known and unknown applications. To the best of our knowledge, this is the first work to use semi-supervised learning techniques for the traffic classification problem. Our approach allows classifiers to be designed from training data that consists of only a few labeled and many unlabeled flows. We consider pragmatic classification issues such as longevity of classifiers and the need for retraining of classifiers. Our performance evaluation using empirical Internet traffic traces that span a 6-month period shows that: (1) high flow and byte classification accuracy (i.e., greater than 90%) can be achieved using training data that consists of a small number of labeled and a large number of unlabeled flows; (2) presence of "mice" and "elephant" flows in the Internet complicates the design of classifiers, especially of those with high byte accuracy, and necessitates the use of weighted sampling techniques to obtain training flows; and (3) retraining of classifiers is necessary only when there are non-transient changes in the network usage characteristics. As a proof of concept, we implement prototype offline and realtime classification systems to demonstrate the feasibility of our approach. © 2007.},
author = {Erman, Jeffrey and Mahanti, Anirban and Arlitt, Martin and Cohen, Ira and Williamson, Carey},
doi = {10.1016/j.peva.2007.06.014},
issn = {01665316},
journal = {Performance Evaluation},
keywords = {Internet traffic classification,Machine learning,Realtime classification,Semi-supervised learning},
month = oct,
number = {9-12},
pages = {1194--1213},
title = {{Offline/realtime traffic classification using semi-supervised learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548118248&partnerID=tZOtx3y1},
volume = {64},
year = {2007}
}
@inproceedings{Ranzato2011,
abstract = {The most popular way to use probabilistic models in vision is first to extract some descriptors of small image patches or object parts using well-engineered features, and then to use statistical learning tools to model the dependencies among these features and eventual labels. Learning probabilistic models directly on the raw pixel values has proved to be much more difficult and is typically only used for regularizing discriminative methods. In this work, we use one of the best, pixel-level, generative models of natural images-a gated MRF-as the lowest level of a deep belief network (DBN) that has several hidden layers. We show that the resulting DBN is very good at coping with occlusion when predicting expression categories from face images, and it can produce features that perform comparably to SIFT descriptors for discriminating different types of scene. The generative ability of the model also makes it easy to see what information is captured and what is lost at each level of representation. © 2011 IEEE.},
author = {Ranzato, Marc'Aurelio and Susskind, Joshua and Mnih, Volodymyr and Hinton, Geoffrey},
booktitle = {CVPR 2011},
doi = {10.1109/CVPR.2011.5995710},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato et al._2011_On deep generative models with applications to recognition.pdf:pdf},
isbn = {978-1-4577-0394-2},
issn = {10636919},
month = jun,
pages = {2857--2864},
publisher = {IEEE},
title = {{On deep generative models with applications to recognition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052877144&partnerID=tZOtx3y1},
year = {2011}
}
@article{Cortes1995,
abstract = {The support-vector network is a new leaming machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high- dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demon- strated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Cortes, Vapnik_1995_Support-vector networks.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers},
pages = {273--297},
pmid = {9052598814225336358},
title = {{Support-vector networks}},
url = {http://link.springer.com/article/10.1007/bf00994018},
volume = {20},
year = {1995}
}
@inproceedings{Collobert2008,
abstract = {We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, sernantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art performance. Copyright 2008 by the author(s)/owner(s).},
author = {Collobert, Ronan and Weston, Jason},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
isbn = {9781605582054},
pages = {160--167},
title = {{A unified architecture for natural language processing: Deep neural networks with multitask learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449095373&partnerID=tZOtx3y1},
year = {2008}
}
@inproceedings{Krizhevsky2012,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton_2012_ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
keywords = {CNN},
mendeley-tags = {CNN},
pages = {1097--1105},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional},
year = {2012}
}
@article{Ji2013,
abstract = {We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.},
author = {Ji, Shuiwang and Yang, Ming and Yu, Kai},
doi = {10.1109/TPAMI.2012.59},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ji, Yang, Yu_2013_3D convolutional neural networks for human action recognition.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Decision Support Techniques,Image Interpretation,Imaging,Movement,Movement: physiology,Neural Networks (Computer),Pattern Recognition,Subtraction Technique,Three-Dimensional,Three-Dimensional: methods},
month = jan,
number = {1},
pages = {221--31},
pmid = {22392705},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{3D convolutional neural networks for human action recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22392705},
volume = {35},
year = {2013}
}
@article{Morgan1995,
abstract = {The HMM/connectionist approach to large vocabulary continuous speech recognition, as the name implies, is a cross between the statistical representations called hidden Markov models and artificial neural network methods. This approach provides a mechanism for incorporating a range of sources of evidence without strong assumptions about their joint statistics, and may have applicability to much more complex systems that can incorporate deep acoustic and linguistic context. The method is intrinsically discriminant and conservative of parameters.},
author = {Morgan, N. and Bourlard, H.},
doi = {10.1109/79.382443},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Morgan, Bourlard_1995_Continuous speech recognition.pdf:pdf},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
month = may,
number = {3},
pages = {24--42},
publisher = {IEEE},
title = {{Continuous speech recognition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0029306621&partnerID=tZOtx3y1},
volume = {12},
year = {1995}
}
@article{LeCun1995,
abstract = {Multilayered perceptrons and some other algorithms are compared in their capacity of classifying handwritten digits},
author = {LeCun, Y and Jackel, L D and Bottou, L and Cortes, C and Denker, J S and Drucker, H and Guyon, I and Muller, U a and Sackinger, E and Simard, P and Vapnik, V and {Yann Lecun, L. D. Jackel, Harris A. Eduard, N Bottou, Corinna Cartes, John S. Denker, Harris Drucker, Eduard Sackinger, Patrice Simard}, Vladimir Vapnik},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1995_Learning Algorithms For Classification A Comparison On Handwritten Digit Recognition.pdf:pdf},
journal = {Neural Networks: The Statistical Mechanics Perspective},
pages = {261--276},
title = {{Learning Algorithms For Classification: A Comparison On Handwritten Digit Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.4628 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.21.4628&amp;rep=rep1&amp;type=pdf},
year = {1995}
}
@article{LeCun1998,
author = {LeCun, Yann and Bengio, Yoshua},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun, Bengio_1998_Convolutional networks for images, speech, and time series.pdf:pdf},
isbn = {0-262-51102-9},
journal = {The handbook of brain theory and neural networks},
month = oct,
pages = {255--258},
publisher = {MIT Press},
title = {{Convolutional networks for images, speech, and time series}},
url = {http://dl.acm.org/citation.cfm?id=303568.303704},
volume = {3361},
year = {1998}
}
@inproceedings{Le2011b,
abstract = {Previous work on action recognition has focused on adapting hand-designed local features, such as SIFT or HOG, from static images to the video domain. In this paper, we propose using unsupervised feature learning as a way to learn features directly from video data. More specifically, we present an extension of the Independent Subspace Analysis algorithm to learn invariant spatio-temporal features from unlabeled video data. We discovered that, despite its simplicity, this method performs surprisingly well when combined with deep learning techniques such as stacking and convolution to learn hierarchical representations. By replacing hand-designed features with our learned features, we achieve classification results superior to all previous published results on the Hollywood2, UCF, KTH and YouTube action recognition datasets. On the challenging Hollywood2 and YouTube action datasets we obtain 53.3% and 75.8% respectively, which are approximately 5% better than the current best published results. Further benefits of this method, such as the ease of training and the efficiency of training and prediction, will also be discussed. You can download our code and learned spatio-temporal features here: http://ai.stanford.edu/wzou/ © 2011 IEEE.},
author = {Le, Quoc V. and Zou, Will Y. and Yeung, Serena Y. and Ng, Andrew Y.},
booktitle = {CVPR 2011},
doi = {10.1109/CVPR.2011.5995496},
isbn = {978-1-4577-0394-2},
issn = {10636919},
month = jun,
pages = {3361--3368},
publisher = {IEEE},
title = {{Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80052874098&partnerID=tZOtx3y1},
year = {2011}
}
@article{Williams2006,
author = {Williams, CKI and Rasmussen, CE},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Williams, Rasmussen_2006_Gaussian processes for machine learning.pdf:pdf},
journal = {the MIT Press},
title = {{Gaussian processes for machine learning}},
url = {http://www-old.newton.ac.uk/programmes/BNR/seminars/2007080914001.pdf},
year = {2006}
}
@article{Bengio2013c,
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
archivePrefix = {arXiv},
arxivId = {1206.5538},
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
doi = {10.1109/TPAMI.2013.50},
eprint = {1206.5538},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Bengio, Courville, Vincent_2013_Representation learning a review and new perspectives.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Artificial Intelligence: trends,Humans,Neural Networks (Computer)},
month = jun,
number = {1993},
pages = {1798--828},
pmid = {23787338},
title = {{Representation learning: a review and new perspectives.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84879854889&partnerID=tZOtx3y1 http://www.ncbi.nlm.nih.gov/pubmed/23787338 http://arxiv.org/abs/1206.5538},
volume = {35},
year = {2013}
}
@inproceedings{QuocV.Le,
abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8% accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative im- provement over the previous state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1112.6209},
author = {Le, Quoc V and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S and Dean, Jeff and Ng, Andrew Y and {Quoc V. Le, Rajat Monga, Matthieu Devin, Kai Chen, Greg S. Corrado, Jeff Dean}, Andrew Y. Ng},
booktitle = {International Conference in Machine Learning},
doi = {10.1109/MSP.2011.940881},
eprint = {1112.6209},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded//Le et al._2011_Building high-level features using large scale unsupervised learning.pdf:pdf},
isbn = {978-1-4799-0356-6},
issn = {10535888},
pages = {38115},
title = {{Building high-level features using large scale unsupervised learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.261.605 http://arxiv.org/abs/1112.6209},
year = {2011}
}
@article{Larochelle2012,
abstract = {Recent developments have demonstrated the capacity of restricted Boltzmann machines (RBM) to be powerful generative models, able to extract useful features from input data or construct deep artificial neural networks. In such settings, the RBMonly yields a preprocessing or an initialization for some other model, instead of acting as a complete supervised model in its own right. In this paper, we argue that RBMs can provide a self-contained framework for developing competitive classifiers. We study the Classification RBM (ClassRBM), a variant on the RBM adapted to the classification setting. We study different strategies for training the ClassRBM and show that competitive classification performances can be reached when appropriately combining discriminative and generative training objectives. Since training according to the generative objective requires the computation of a generally intractable gradient, we also compare different approaches to estimating this gradient and address the issue of obtaining such a gradient for problems with very high dimensional inputs. Finally, we describe how to adapt the ClassRBM to two special cases of classification problems, namely semi-supervised and multitask learning. © 2012 Hugo Larochelle, Michael Mandel, Razvan Pascanu and Yoshua Bengio.},
author = {Larochelle, Hugo and Mandel, Michael and Pascanu, Razvan and Bengio, Yoshua},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Larochelle et al._2012_Learning algorithms for the classification restricted Boltzmann machine.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Classification,Discriminative learning,Generative learning,Restricted Boltzmannmachine},
pages = {643--669},
title = {{Learning algorithms for the classification restricted Boltzmann machine}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84859473821&partnerID=tZOtx3y1},
volume = {13},
year = {2012}
}
@inproceedings{Nair2009,
abstract = {We introduce a new type of top-level model for Deep Belief Nets and evaluate it on a 3D object recognition task. The top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients. Performance is evaluated on the NORB database (normalized-uniform version), which contains stereo-pair images of objects under different lighting conditions and viewpoints. Our model achieves 6.5% error on the test set, which is close to the best published result for NORB (5.9%) using a convolutional neural net that has built-in knowledge of translation invariance. It substantially outperforms shallow models such as SVMs (11.6%). DBNs are especially suited for semi-supervised learning, and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database. With the extra unlabeled data (and the same amount of labeled data as before), our model achieves 5.2% error.},
author = {Nair, Vinod and Hinton, Geoffrey E.},
booktitle = {Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference},
isbn = {9781615679119},
pages = {1339--1347},
title = {{3D object recognition with Deep Belief Nets}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-78149306047&partnerID=tZOtx3y1},
year = {2009}
}
@article{G.E.Hinton,
author = {{G. E. Hinton, A. Krizhevsky}, S. D. Wang},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/G. E. Hinton, A. Krizhevsky_2011_Transforming Auto-encoders(2).pdf:pdf},
journal = {Artificial Neural Networks and Machine Learning–ICANN 2011.},
keywords = {Vision},
mendeley-tags = {Vision},
pages = {44--51.},
title = {{Transforming Auto-encoders}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.220.5099},
year = {2011}
}
@article{Santos2014,
author = {Santos, CD and Zadrozny, B},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Santos, Zadrozny_2014_Learning Character-level Representations for Part-of-Speech Tagging.pdf:pdf},
journal = {Proceedings of the 31st International Conference on Machine Learning},
pages = {1818--1826},
title = {{Learning Character-level Representations for Part-of-Speech Tagging}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2014c2_santos14},
volume = {ICML-14},
year = {2014}
}
@article{Chen2014,
author = {Chen, X and Lin, X},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Chen, Lin_2014_Big Data Deep Learning Challenges and Perspectives.pdf:pdf},
title = {{Big Data Deep Learning: Challenges and Perspectives}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6817512},
year = {2014}
}
@article{Li2009,
abstract = {Motivated by the importance of accurate identification for a range of applications, this paper compares and contrasts the effective and efficient classification of network-based applications using behavioral observations of network-traffic and those using deep-packet inspection. Importantly, throughout our work we are able to make comparison with data possessing an accurate, independently determined ground-truth that describes the actual applications causing the network-traffic observed. In a unique study in both the spatial-domain: comparing across different network-locations and in the temporal-domain: comparing across a number of years of data, we illustrate the decay in classification accuracy across a range of application-classification mechanisms. Further, we document the accuracy of spatial classification without training data possessing spatial diversity. Finally, we illustrate the classification of UDP traffic. We use the same classification approach for both stateful flows (TCP) and stateless flows based upon UDP. Importantly, we demonstrate high levels of accuracy: greater than 92% for the worst circumstance regardless of the application. © 2008 Elsevier B.V. All rights reserved.},
author = {Li, Wei and Canini, Marco and Moore, Andrew W. and Bolla, Raffaele},
doi = {10.1016/j.comnet.2008.11.016},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Li et al._2009_Efficient application identification and the temporal and spatial stability of classification schema.pdf:pdf},
issn = {13891286},
journal = {Computer Networks},
keywords = {Application identification,Deep-packet inspection,Machine learning,Spatial stability,Temporal decay,Traffic classification},
month = apr,
number = {6},
pages = {790--809},
title = {{Efficient application identification and the temporal and spatial stability of classification schema}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-61749100211&partnerID=tZOtx3y1},
volume = {53},
year = {2009}
}
@article{Lehman2014,
abstract = {Artificial intelligence (AI) is a sprawling field encompassing a diversity of approaches to machine intelligence and disparate perspectives on how intelligence should be viewed. Because researchers often engage only within their own specialized area of AI, there are many interesting broad questions about AI as a whole that often go unanswered. How should intelligence be abstracted in AI research? Which subfields, techniques, and abstractions are most promising? Why do researchers bet their careers on the particular abstractions and techniques of their chosen subfield of AI? Should AI research be "bio-inspired" and remain faithful to the process that produced intelligence (evolution) or the biological substrate that enables it (networks of neurons)? Discussing these big-picture questions motivated us to organize an AAAI Fall Symposium, which gathered participants across AI subfields to present and debate their views. This article distills the resulting insights.},
author = {Lehman, Joel and Clune, Jeff and Risi, Sebastian},
doi = {10.1109/MIS.2014.92},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lehman, Clune, Risi_2014_An Anarchy of Methods Current Trends in How Intelligence Is Abstracted in AI.pdf:pdf},
issn = {1541-1672},
journal = {Intelligent Systems, IEEE},
keywords = {AI,AI abstraction,AI research,AI subfields,AI techniques,Adaptive systems,Artificial intelligence,Biological system modeling,Brain modeling,Computational modeling,Design methodology,Neural networks,Neuroscience,Robots,adaptive systems,artificial intelligence,bio-inspired research,cognitive science,computational neuroscience,deep learning,design automation,developmental robotics,evolving neural networks,intelligent systems,machine intelligence,neuroevolution},
month = nov,
number = {6},
pages = {56--62},
shorttitle = {Intelligent Systems, IEEE},
title = {{An Anarchy of Methods: Current Trends in How Intelligence Is Abstracted in AI}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6982117 http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982117},
volume = {29},
year = {2014}
}
@inproceedings{Simard2003,
abstract = {Not Available},
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
booktitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.},
doi = {10.1109/ICDAR.2003.1227801},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Simard, Steinkraus, Platt_2003_Best practices for convolutional neural networks applied to visual document analysis.pdf:pdf},
isbn = {0-7695-1960-1},
keywords = {Best practices,CNN,Concrete,Convolution,Handwriting recognition,Industrial training,Information processing,Neural networks,Performance analysis,Support vector machines,Text analysis},
mendeley-tags = {CNN},
pages = {958--963},
publisher = {IEEE Comput. Soc},
shorttitle = {Document Analysis and Recognition, 2003. Proceedin},
title = {{Best practices for convolutional neural networks applied to visual document analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1227801},
volume = {1},
year = {2003}
}
@article{Dean2012,
abstract = {Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm},
author = {Dean, Jeffrey and Corrado, Greg S and Monga, Rajat and Chen, Kai and Devin, Matthieu and Le, Quoc V and Mao, Mark Z and Ranzato, Marc Aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and Ng, Andrew Y},
isbn = {9781627480031},
issn = {10495258},
journal = {NIPS 2012: Neural Information Processing Systems},
pages = {1--11},
title = {{Large Scale Distributed Deep Networks}},
year = {2012}
}
@article{LeCun1998a,
abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day},
author = {LeCun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
doi = {10.1109/5.726791},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1998_Gradient-based learning applied to document recognition.pdf:pdf;:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1998_Gradient-based learning applied to document recognition(2).pdf:pdf},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {2D shape variability,Character recognition,Feature extraction,GTN,Hidden Markov models,Machine learning,Multi-layer neural network,Neural networks,Optical character recognition software,Optical computing,Pattern recognition,Principal component analysis,back-propagation,backpropagation,cheque reading,complex decision surface synthesis,convolution,convolutional neural network character recognizers,document recognition,document recognition systems,field extraction,gradient based learning technique,gradient-based learning,graph transformer networks,handwritten character recognition,handwritten digit recognition task,high-dimensional patterns,language modeling,multilayer neural networks,multilayer perceptrons,multimodule systems,optical character recognition,performance measure minimization,segmentation recognition},
number = {11},
pages = {2278--2324},
shorttitle = {Proceedings of the IEEE},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=726791 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=726791},
volume = {86},
year = {1998}
}
@article{Ranzato2007,
abstract = {We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces "stroke detectors" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.},
author = {Ranzato, Marc Aurelio and Poultney, Christopher and Chopra, Sumit and Lecun, Yann},
isbn = {9780262195683},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
pages = {1137--1134},
title = {{Efficient Learning of Sparse Representations with an Energy-Based Model}},
volume = {19},
year = {2007}
}
@inproceedings{Huang2012,
abstract = {Most modern face recognition systems rely on a feature representation given by a hand-crafted image descriptor, such as Local Binary Patterns (LBP), and achieve improved performance by combining several such representations. In this paper, we propose deep learning as a natural source for obtaining additional, complementary representations. To learn features in high-resolution images, we make use of convolutional deep belief networks. Moreover, to take advantage of global structure in an object class, we develop local convolutional restricted Boltzmann machines, a novel convolutional learning model that exploits the global structure by not assuming stationarity of features across the image, while maintaining scalability and robustness to small misalignments. We also present a novel application of deep learning to descriptors other than pixel intensity values, such as LBP. In addition, we compare performance of networks trained using unsupervised learning against networks with random filters, and empirically show that learning weights not only is necessary for obtaining good multilayer representations, but also provides robustness to the choice of the network architecture parameters. Finally, we show that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors. Moreover, by combining these representations, we achieve state-of-the-art results on a real-world face verification database. © 2012 IEEE.},
author = {Huang, G. B. and Learned-Miller, E.},
booktitle = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2012.6247968},
isbn = {978-1-4673-1228-8},
issn = {10636919},
month = jun,
pages = {2518--2525},
publisher = {IEEE},
title = {{Learning hierarchical representations for face verification with convolutional deep belief networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84866691616&partnerID=tZOtx3y1},
year = {2012}
}
@inproceedings{Vincent2008,
abstract = {Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite. Copyright 2008 by the author(s)/owner(s).},
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre Antoine},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Vincent et al._2008_Extracting and composing robust features with denoising autoencoders.pdf:pdf},
isbn = {9781605582054},
pages = {1096--1103},
title = {{Extracting and composing robust features with denoising autoencoders}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449089103&partnerID=tZOtx3y1},
year = {2008}
}
@article{Egmont-Petersen2002,
abstract = {We review more than 200 applications of neural networks in image processing and discuss the present and possible future role of neural networks, especially feed-forward neural networks, Kohonen feature maps and Hopfield neural networks. The various applications are categorised into a novel two-dimensional taxonomy for image processing algorithms. One dimension specifies the type of task performed by the algorithm: preprocessing, data reduction/feature extraction, segmentation, object recognition, image understanding and optimisation. The other dimension captures the abstraction level of the input data processed by the algorithm: pixel-level, local feature-level, structure-level, object-level, object-set-level and scene characterisation. Each of the six types of tasks poses specific constraints to a neural-based approach. These specific conditions are discussed in detail. A synthesis is made of unresolved problems related to the application of pattern recognition techniques in image processing and specifically to the application of neural networks. Finally, we present an outlook into the future application of neural networks and relate them to novel developments.},
author = {Egmont-Petersen, M. and de Ridder, D. and Handels, H.},
doi = {10.1016/S0031-3203(01)00178-9},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Egmont-Petersen, de Ridder, Handels_2002_Image processing with neural networks—a review.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Digital image processing,Feature extraction,Image compression,Image understanding,Invariant pattern recognition,Neural networks,Object recognition,Optimization,Preprocessing,Segmentation},
month = oct,
number = {10},
pages = {2279--2301},
title = {{Image processing with neural networks—a review}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320301001789},
volume = {35},
year = {2002}
}
@inproceedings{Glorot2011,
abstract = {The exponential increase in the availability of online reviews and recommendations makes sentiment classification an interesting topic in academic and industrial research. Reviews can span so many different domains that it is difficult to gather annotated training data for all of them. Hence, this paper studies the problem of domain adaptation for sentiment classifiers, hereby a system is trained on labeled reviews from one source domain but is meant to be deployed on another. We propose a deep learning approach which learns to extract a meaningful representation for each review in an unsupervised fashion. Sentiment classifiers trained with this high-level feature representation clearly outperform state-of-the-art methods on a benchmark composed of reviews of 4 types of Amazon products. Furthermore, this method scales well and allowed us to successfully perform domain adaptation on a larger industrial-strength dataset of 22 domains. Copyright 2011 by the author(s)/owner(s).},
author = {Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
booktitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
isbn = {9781450306195},
pages = {513--520},
title = {{Domain adaptation for large-scale sentiment classification: A deep learning approach}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053443013&partnerID=tZOtx3y1},
year = {2011}
}
@article{Chi1994,
abstract = {Learning involves the integration of new information into existing knowledge. Generating explanations to oneself (self-explaining) facilitates that integration process. Previously, self-explanation has been shown to improve the acquisition of problem-solving skills when studying worked-out examples. This study extends that finding, showing that self-explanation can also be facilitative when it is explicitly promoted, in the context of learning declarative knowledge from an expository text. Without any extensive training, 14 eighth-grade students were merely asked to self-explain after reading each line of a passage on the human circulatory system. Ten students in the control group read the same text twice, but were not prompted to self-explain. All of the students were tested for their circulatory system knowledge before and after reading the text. The prompted group had a greater gain from the pretest to the posttest. Moreover, prompted students who generated a large number of self-explanations (the high explainers) learned with greater understanding than low explainers. Understanding was assessed by answering very complex questions and inducing the function of a component when it was only implicitly stated. Understanding was further captured by a mental model analysis of the self-explanation protocols. High explainers all achieved the correct mental model of the circulatory system, whereas many of the unprompted students as well as the low explainers did not. Three processing characteristics of self-explaining are considered as reasons for the gains in deeper understanding. © 1994.},
author = {Chi, M},
doi = {10.1016/0364-0213(94)90016-7},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Chi_1994_Eliciting self-explanations improves understanding.pdf:pdf},
issn = {03640213},
journal = {Cognitive Science},
month = sep,
number = {3},
pages = {439--477},
title = {{Eliciting self-explanations improves understanding}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-43949150689&partnerID=tZOtx3y1},
volume = {18},
year = {1994}
}
@book{Bertin-Mahieux2011,
abstract = {Recently there has been a great deal of attention paid to the automatic prediction of tags for music and audio in general. Social tags are user-generated keywords associated with some resource on the Web. In the case of music, social tags have become an important component of "Web 2.0" recommender systems. There have been many attempts at automatically applying tags to audio for different purposes: database management, music recommendation, improved human-computer interfaces, estimating similarity among songs, and so on. Many published results show that this problem can be tackled using machine learning techniques, however, no method so far has been proven to be particularly suited to the task. First, it seems that no one has yet found an appropriate algorithm to solve this challenge. But second, the task definition itself is problematic. In an effort to better understand the task and also to help new researchers bring their insights to bear on this problem, this chapter provides a review of the state-of-the-art methods for addressing automatic tagging of audio. It is divided in the following sections: goal, framework, audio representation, labeled data, classification, evaluation, and future directions. Such a division helps understand the commonalities and strengths of the different methods that have been proposed. © 2011, IGI Global.},
author = {Bertin-Mahieux, Thierry and Eck, Douglas and Mandel, Michael},
booktitle = {Machine Audition: Principles, Algorithms and Systems},
doi = {10.4018/978-1-61520-919-4},
editor = {Wang, Wenwu},
isbn = {9781615209194},
pages = {334--352},
publisher = {IGI Global},
title = {{Machine Audition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80051647410&partnerID=tZOtx3y1},
year = {2011}
}
@article{Larochelle2009,
abstract = {Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms.},
author = {Larochelle, Hugo and Bengio, Yoshua and Louradour, J\'{e}r\^{o}me and Lamblin, Pascal},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Artificial neural networks,Autoassociators,Deep belief networks,Restricted Boltzmann machines,Unsupervised learning},
pages = {1--40},
title = {{Exploring strategies for training deep neural networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-59449087310&partnerID=tZOtx3y1},
volume = {10},
year = {2009}
}
@inproceedings{Weston2008,
abstract = {We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques. Copyright 2008 by the author(s)/owner(s).},
author = {Weston, Jason and Ratle, Fr\'{e}d\'{e}ric and Collobert, Ronan},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
isbn = {9781605582054},
pages = {1168--1175},
title = {{Deep learning via semi-supervised embedding}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-56449119888&partnerID=tZOtx3y1},
year = {2008}
}
@incollection{Bengio2007,
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), rea- soning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, withmin- imal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally lim- ited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very ineffi- cient in terms of required number of computational elements and examples. Sec- ond, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learn- ing) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more ab- stract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence. 1},
author = {Bengio, Yoshua and {LeCun}, Yann},
booktitle = {Large Scale Kernel Machines},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, {LeCun}_2007_Scaling Learning Algorithms towards AI.pdf:pdf},
isbn = {1002620262},
pages = {321--360},
title = {{Scaling Learning Algorithms towards AI}},
url = {http://www.iro.umontreal.ca/$\sim$lisa/bib/pub_subject/language/pointeurs/bengio+lecun-chapter2007.pdf},
year = {2007}
}
@article{Hinton2007,
abstract = {To achieve its impressive performance in tasks such as speech perception or object recognition, the brain extracts multiple levels of representation from the sensory input. Backpropagation was the first computationally efficient model of how neural networks could learn multiple layers of representation, but it required labeled training data and it did not work well in deep networks. The limitations of backpropagation learning can now be overcome by using multilayer neural networks that contain top-down connections and training them to generate sensory data rather than to classify it. Learning multilayer generative models might seem difficult, but a recent discovery makes it easy to learn nonlinear distributed representations one layer at a time.},
author = {Hinton, Geoffrey E},
doi = {10.1016/j.tics.2007.09.004},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Hinton_2007_Learning multiple layers of representation.pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Brain,Brain: physiology,Humans,Learning,Learning: physiology,Models,Nerve Net,Nerve Net: physiology,Psychological},
month = oct,
number = {10},
pages = {428--34},
pmid = {17921042},
title = {{Learning multiple layers of representation.}},
url = {http://www.sciencedirect.com/science/article/pii/S1364661307002173},
volume = {11},
year = {2007}
}
@inproceedings{Xue2008,
abstract = {Most classification algorithms are best at categorizing the Web documents into a few categories, such as the top two levels in the Open Directory Project. Such a classification method does not give very detailed topic-related class information for the user because the first two levels are often too coarse. However, classification on a large-scale hierarchy is known to be intractable for many target categories with cross-link relationships among them. In this paper, we propose a novel deep-classification approach to categorize Web documents into categories in a large-scale taxonomy. The approach consists of two stages: a search stage and a classification stage. In the first stage, a category-search algorithm is used to acquire the category candidates for a given document. Based on the category candidates, we prune the large-scale hierarchy to focus our classification effort on a small subset of the original hierarchy. As a result, the classification model is trained on the small subset before being applied to assign the category for a new document. Since the category candidates are sufficiently close to each other in the hierarchy, a statistical-language-model based classifier using n-gram features is exploited. Furthermore, the structure of the taxonomy can be utilized in this stage to improve the performance of classification. We demonstrate the performance of our proposed algorithms on the Open Directory Project with, over 130,000 categories. Experimental results show that our proposed approach can reach 51.8% on the measure of Mi-Fl at the 5th level, which is 77.7% improvement over top-down based SVM classification algorithms. Copyright 2008 ACM.},
address = {New York, New York, USA},
author = {Xue, Gui-Rong and Xing, Dikan and Yang, Qiang and Yu, Yong},
booktitle = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval - SIGIR '08},
doi = {10.1145/1390334.1390440},
isbn = {9781605581644},
keywords = {Deep classification,Hierarchical classification,Large scale hierarchy},
pages = {619},
publisher = {ACM Press},
title = {{Deep classification in large-scale text hierarchies}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-57349177558&partnerID=tZOtx3y1},
year = {2008}
}
@article{Bottou1992,
author = {Bottou, L and Vapnik, V},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bottou, Vapnik_1992_Local learning algorithms.pdf:pdf},
journal = {Neural computation},
title = {{Local learning algorithms}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1992.4.6.888},
year = {1992}
}
@article{Bengio2009,
abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the stateof-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks. © 2009 Y. Bengio.},
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2009_Learning deep architectures for AI.pdf:pdf},
issn = {1935-8237},
journal = {Foundations and trends® in Machine Learning},
number = {1},
pages = {1--127},
title = {{Learning deep architectures for AI}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-69349090197&partnerID=tZOtx3y1 http://dl.acm.org/citation.cfm?id=1658424},
volume = {2},
year = {2009}
}
@article{Zouaq2011,
abstract = {Open ontology learning is the process of extracting a domain ontology from a knowledge source in an unsupervised way. Due to its unsupervised nature, it requires filtering mechanisms to rate the importance and correctness of the extracted knowledge. This paper presents OntoCmaps, a domain-independent and open ontology learning tool that extracts deep semantic representations from corpora. OntoCmaps generates rich conceptual representations in the form of concept maps and proposes an innovative filtering mechanism based on metrics from graph theory. Our results show that using metrics such as Betweenness, PageRank, Hits and Degree centrality outperforms the results of standard text-based metrics (TF-IDF, term frequency) for concept identification. We propose voting schemes based on these metrics that provide a good performance in relationship identification, which again provides better results (in terms of precision and F-measure) than other traditional metrics such as frequency of co-occurrences. The approach is evaluated against a gold standard and is compared to the ontology learning tool Text2Onto. The OntoCmaps generated ontology is more expressive than Text2Onto ontology especially in conceptual relationships and leads to better results in terms of precision, recall and F-measure. © 2011 Elsevier B.V.},
author = {Zouaq, Amal and Gasevic, Dragan and Hatala, Marek},
doi = {10.1016/j.is.2011.03.005},
issn = {03064379},
journal = {Information Systems},
keywords = {Filtering,Graph theory,Metrics,Ontology learning},
month = nov,
number = {7},
pages = {1064--1081},
title = {{Towards open ontology learning and filtering}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-79958101810&partnerID=tZOtx3y1},
volume = {36},
year = {2011}
}
@article{Rodd2004,
abstract = {Most words in English are ambiguous between different interpretations; words can mean different things in different contexts. We investigate the implications of different types of semantic ambiguity for connectionist models of word recognition. We present a model in which there is competition to activate distributed semantic representations. The model performs well on the task of retrieving the different meanings of ambiguous words, and is able to simulate data reported by Rodd, Gaskell, and Marslen-Wilson [J. Mem. Lang. 46 (2002) 245] on how semantic ambiguity affects lexical decision performance. In particular, the network shows a disadvantage for words with multiple unrelated meanings (e.g., bark) that coexists with a benefit for words with multiple related word senses (e.g., twist). The ambiguity disadvantage arises because of interference between the different meanings, while the sense benefit arises because of differences in the structure of the attractor basins formed during learning. Words with few senses develop deep, narrow attractor basins, while words with many senses develop shallow, broad basins. We conclude that the mental representations of word meanings can be modelled as stable states within a high-dimensional semantic space, and that variations in the meanings of words shape the landscape of this space. © 2003 Cognitive Science Society, Inc. All rights reserved.},
author = {Rodd, J},
doi = {10.1016/j.cogsci.2003.08.002},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Connectionist networks,Distributed representations,Lexical ambiguity,Lexical decision,Semantic ambiguity,Word recognition},
month = feb,
number = {1},
pages = {89--104},
title = {{Modelling the effects of semantic ambiguity in word recognition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-1142303068&partnerID=tZOtx3y1},
volume = {28},
year = {2004}
}
@inproceedings{Ngiam2011a,
abstract = {Deep networks have been successfully applied to unsupervised feature learning for single modalities (e.g., text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (e.g., video) can be learned ifmultiple modalities (e.g., audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evalu- ate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our mod- els are validated on the CUAVE and AVLet- ters datasets on audio-visual speech classifi- cation, demonstrating best published visual speech classification on AVLetters and effec- tive shared representation learning.},
author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y.},
booktitle = {Proceedings of The 28th International Conference on Machine Learning (ICML)},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ngiam et al._2011_Multimodal Deep Learning.pdf:pdf},
isbn = {9781450306195},
pages = {689--696},
title = {{Multimodal Deep Learning}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-80053437179&partnerID=tZOtx3y1},
year = {2011}
}
@article{Deng2013,
abstract = {This book is aimed to provide an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria: 1) expertise or knowledge of the authors; 2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and 3) the application areas that have the potential to be impacted significantly by deep learning and that have gained concentrated research efforts, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning. In Chapter 1, we provide the background of deep learning, as intrinsically connected to the use of multiple layers of nonlinear transformations to derive features from the sensory signals such as speech and visual images. In the most recent literature, deep learning is embodied also as representation learning, which involves a hierarchy of features or concepts where higher-level representations of them are defined from lower-level ones and where the same lower-level representations help to define higher-level ones. In Chapter 2, a brief historical account of deep learning is presented. In particular, selected chronological development of speech recognition is used to illustrate the recent impact of deep learning that has become a dominant technology in speech recognition industry within only a few years since the start of a collaboration between academic and industrial researchers in applying deep learning to speech recognition. In Chapter 3, a three-way classification scheme for a large body of work in deep learning is developed. We classify a growing number of deep learning techniques into unsupervised, supervised, and hybrid categories, and present qualitative descriptions and a literature survey for each category. From Chapter 4 to Chapter 6, we discuss in detail three popular deep networks and related learning methods, one in each category. Chapter 4 is devoted to deep autoencoders as a prominent example of the unsupervised deep learning techniques. Chapter 5 gives a major example in the hybrid deep network category, which is the discriminative feed-forward neural network for supervised learning with many layers initialized using layer-by-layer generative, unsupervised pre-training. In Chapter 6, deep stacking networks and several of the variants are discussed in detail, which exemplify the discriminative or supervised deep learning techniques in the three-way categorization scheme. In Chapters 7-11, we select a set of typical and successful applications of deep learning in diverse areas of signal and information processing and of applied artificial intelligence. In Chapter 7, we review the applications of deep learning to speech and audio processing, with emphasis on speech recognition organized according to several prominent themes. In Chapters 8, we present recent results of applying deep learning to language modeling and natural language processing. Chapter 9 is devoted to selected applications of deep learning to information retrieval including Web search. In Chapter 10, we cover selected applications of deep learning to image object recognition in computer vision. Selected applications of deep learning to multi-modal processing and multi-task learning are reviewed in Chapter 11. Finally, an epilogue is given in Chapter 12 to summarize what we presented in earlier chapters and to discuss future challenges and directions.},
author = {Deng, Li and Yu, Dong},
doi = {10.1136/bmj.319.7209.0a},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng, Yu_2013_Deep Learning Methods and Applications.pdf:pdf},
isbn = {9781405161251},
issn = {09598138},
journal = {Foundations and Trends in Signal Processing},
pages = {197----387},
pmid = {10463930},
title = {{Deep Learning: Methods and Applications}},
volume = {7},
year = {2013}
}
@inproceedings{Raina2009,
abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
booktitle = {Proceedings of the 26th International Conference On Machine Learning, ICML 2009},
isbn = {9781605585161},
pages = {873--880},
title = {{Large-scale deep unsupervised learning using graphics processors}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-71149105669&partnerID=tZOtx3y1},
year = {2009}
}
@article{Lawrence1997,
abstract = {We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer.},
author = {Lawrence, S and Giles, C L and Tsoi, A C and Back, A D},
doi = {10.1109/72.554195},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Lawrence et al._1997_Face recognition a convolutional neural-network approach.pdf:pdf},
issn = {1045-9227},
journal = {IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council},
keywords = {CNN,Face recognition,Feature extraction,Humans,Image databases,Image sampling,Karhunen-Loeve transforms,Multilayer perceptrons,Neural networks,Quantization,Spatial databases,computational complexity,convolution,convolutional neural-network,dimensionality reduction,face recognition,feature extraction,image matching,invariance,local image sampling,quantisation (signal),quantization,self-organising feature maps,self-organizing map,template matching,topological space,topology},
mendeley-tags = {CNN},
month = jan,
number = {1},
pages = {98--113},
pmid = {18255614},
shorttitle = {Neural Networks, IEEE Transactions on},
title = {{Face recognition: a convolutional neural-network approach.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255614},
volume = {8},
year = {1997}
}
@article{Farabet2013,
abstract = {Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a $(320\times 240)$ image labeling in less than a second, including feature extraction.},
author = {Farabet, Cl\'{e}ment and Couprie, Camille and Najman, Laurent and Lecun, Yann},
doi = {10.1109/TPAMI.2012.231},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Convolutional networks,deep learning,image classification,image segmentation,scene parsing},
month = aug,
number = {8},
pages = {1915--29},
pmid = {23787344},
title = {{Learning hierarchical features for scene labeling.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84876258641&partnerID=tZOtx3y1},
volume = {35},
year = {2013}
}
@inproceedings{Sainath2012,
abstract = {Neural network (NN) bottleneck (BN) features are typically created by training a NN with a middle bottleneck layer. Recently, an alternative structure was proposed which trains a NN with a constant number of hidden units to predict output targets, and then reduces the dimensionality of these output probabilities through an auto-encoder, to create auto-encoder bottleneck (AE-BN) features. The benefit of placing the BN after the posterior estimation network is that it avoids the loss in frame classification accuracy incurred by networks that place the BN before the softmax. In this work, we investigate the use of pre-training when creating AE-BN features. Our experiments indicate that with the AE-BN architecture, pre-trained and deeper NNs produce better AE-BN features. On a 50-hour English Broadcast News task, the AE-BN features provide over a 1% absolute improvement compared to a state-of-the-art GMM/HMM with a WER of 18.8% and pre-trained NN hybrid system with a WER of 18.4%. In addition, on a larger 430-hour Broadcast News task, AE-BN features provide a 0.5% absolute improvement over a strong GMM/HMM baseline with a WER of 16.0%. Finally, system combination with the GMM/HMM baseline and AE-BN systems provides an additional 0.5% absolute on 430 hours over the AE-BN system alone, yielding a final WER of 15.0%. © 2012 IEEE.},
author = {Sainath, Tara N. and Kingsbury, Brian and Ramabhadran, Bhuvana},
booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2012.6288833},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Sainath, Kingsbury, Ramabhadran_2012_Auto-encoder bottleneck features using deep belief networks.pdf:pdf},
isbn = {978-1-4673-0046-9},
issn = {15206149},
keywords = {Deep Belief Networks,Speech Recognition},
month = mar,
pages = {4153--4156},
publisher = {IEEE},
title = {{Auto-encoder bottleneck features using deep belief networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84867593213&partnerID=tZOtx3y1},
year = {2012}
}
@article{LeRoux2008,
abstract = {Deep belief networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton, Osindero, and Teh (2006) along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a restricted Boltzmann machine (RBM), used to represent one layer of the model. Restricted Boltzmann machines are interesting because inference is easy in them and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modeling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs.},
author = {{Le Roux}, Nicolas and Bengio, Yoshua},
doi = {10.1162/neco.2008.04-07-510},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Le Roux, Bengio_2008_Representational power of restricted boltzmann machines and deep belief networks.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Animals,Computer Simulation,Computer-Assisted,Humans,Learning,Learning: physiology,Models,Neural Networks (Computer),Signal Processing,Statistical},
month = jun,
number = {6},
pages = {1631--49},
pmid = {18254699},
title = {{Representational power of restricted boltzmann machines and deep belief networks.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-45749110924&partnerID=tZOtx3y1},
volume = {20},
year = {2008}
}
@article{Ji2014a,
abstract = {Text-level discourse parsing is notoriously difficult, as distinctions between discourse relations require subtle semantic judg- ments that are not easily captured using standard features. In this paper, we present a representation learning approach, in which we transform surface features into a latent space that facilitates RST dis- course parsing. By combining the machin- ery of large-margin transition-based struc- tured prediction with representation learn- ing, our method jointly learns to parse dis- course while at the same time learning a discourse-driven projection of surface fea- tures. The resulting shift-reduce discourse parser obtains substantial improvements over the previous state-of-the-art in pre- dicting relations and nuclearity on the RST Treebank.},
author = {Ji, Yangfeng and Eisenstein, Jacob},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ji, Eisenstein_2014_Representation learning for text-level discourse parsing.pdf:pdf},
isbn = {9781937284725},
journal = {Proceedings of the 52nd Annual Meeting of the  \ldots},
pages = {13--24},
title = {{Representation learning for text-level discourse parsing}},
url = {http://www.cc.gatech.edu/grads/y/yji37/papers/ji-acl-2014.pdf},
year = {2014}
}
@article{Poultney2006,
author = {Ranzato, M. and Poultney, C and Chopra, S and Cun, YL},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato et al._2006_Efficient learning of sparse representations with an energy-based model.pdf:pdf},
journal = {Advances in neural \ldots},
title = {{Efficient learning of sparse representations with an energy-based model}},
url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2006_804.pdf},
year = {2006}
}
@inproceedings{Boser1992,
abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of classifiaction functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms. 1 INTRODUCTION Good generalization performance of pattern classifiers is achieved when the capacity of the classification function is matched to the size of the training set. Classifiers with a large numb...},
author = {Boser, Bernhard E. and Guyon, IM Isabelle M. and Vapnik, VN Vladimir N.},
booktitle = {Proceedings of the fifth annual workshop on Computational learning theory},
doi = {10.1.1.21.3818},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Boser, Guyon, Vapnik_1992_A Training Algorithm for Optimal Margin Classifiers.pdf:pdf},
isbn = {089791497X},
issn = {0-89791-497-X},
pages = {144--152},
title = {{A Training Algorithm for Optimal Margin Classifiers}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.3818 http://dl.acm.org/citation.cfm?id=130401},
year = {1992}
}
@article{LeCun1989,
abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
doi = {10.1162/neco.1989.1.4.541},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/LeCun et al._1989_Backpropagation Applied to Handwritten Zip Code Recognition.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
keywords = {CNN},
language = {en},
mendeley-tags = {CNN},
month = dec,
number = {4},
pages = {541--551},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541#.VOiy7DTkdNo},
volume = {1},
year = {1989}
}
@article{Bengio2009b,
author = {Bengio, Y and Delalleau, O},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, Delalleau_2009_Justifying and generalizing contrastive divergence.pdf:pdf},
journal = {Neural Computation},
title = {{Justifying and generalizing contrastive divergence}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.11-07-647},
year = {2009}
}
@article{Bengio2013,
abstract = {Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling deep learning algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges.},
archivePrefix = {arXiv},
arxivId = {1305.0445},
author = {Bengio, Yoshua},
eprint = {1305.0445},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio_2013_Deep Learning of Representations Looking Forward.pdf:pdf},
month = may,
title = {{Deep Learning of Representations: Looking Forward}},
url = {http://arxiv.org/abs/1305.0445},
year = {2013}
}
@inproceedings{Dahl2013,
abstract = {Recently, pre-trained deep neural networks (DNNs) have outperformed traditional acoustic models based on Gaussian mixture models (GMMs) on a variety of large vocabulary speech recognition benchmarks. Deep neural nets have also achieved excellent results on various computer vision tasks using a random 'dropout' procedure that drastically improves generalization error by randomly omitting a fraction of the hidden units in all layers. Since dropout helps avoid over-fitting, it has also been successful on a small-scale phone recognition task using larger neural nets. However, training deep neural net acoustic models for large vocabulary speech recognition takes a very long time and dropout is likely to only increase training time. Neural networks with rectified linear unit (ReLU) non-linearities have been highly successful for computer vision tasks and proved faster to train than standard sigmoid units, sometimes also improving discriminative performance. In this work, we show on a 50-hour English Broadcast News task that modified deep neural networks using ReLUs trained with dropout during frame level training provide an 4.2% relative improvement over a DNN trained with sigmoid units, and a 14.4% relative improvement over a strong GMM/HMM system. We were able to obtain our results with minimal human hyper-parameter tuning using publicly available Bayesian optimization code. © 2013 IEEE.},
author = {Dahl, George E. and Sainath, Tara N. and Hinton, Geoffrey E.},
booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
doi = {10.1109/ICASSP.2013.6639346},
isbn = {978-1-4799-0356-6},
issn = {15206149},
keywords = {Bayesian optimization,LVCSR,acoustic modeling,broadcast news,deep learning,dropout,neural networks,rectified linear units},
month = may,
pages = {8609--8613},
publisher = {IEEE},
title = {{Improving deep neural networks for LVCSR using rectified linear units and dropout}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84890527827&partnerID=tZOtx3y1},
year = {2013}
}
@article{Teh2006,
abstract = {We consider problems involving groups of data where each observation within a group is a draw from a mixture model and where it is desirable to share mixture components between groups. We assume that the number of mixture components is unknown a priori and is to be inferred from the data. In this setting it is natural to consider sets of Dirichlet processes, one for each group, where the well-known clustering properly of the Dirichlet process provides a nonparametric prior for the number of mixture components within each group. Given our desire to tie the mixture models in the various groups, we consider a hierarchical model, specifically one in which the base measure for the child Dirichlet processes is itself distributed according to a Dirichlet process. Such a base measure being discrete, the child Dirichlet processes necessarily share atoms. Thus, as desired, the mixture models in the different groups necessarily share mixture components. We discuss representations of hierarchical Dirichlet processes in terms of a stick-breaking process, and a generalization of the Chinese restaurant process that we refer to as the "Chinese restaurant franchise." We present Markov chain Monte Carlo algorithms for posterior inference in hierarchical Dirichlet process mixtures and describe applications to problems in information retrieval and text modeling. © 2006 American Statistical Association.},
author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
doi = {10.1198/016214506000000302},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Clustering,Hierarchical model,Markov chain Monte Carlo,Mixture model,Nonparametric Bayesian statistics},
month = dec,
number = {476},
pages = {1566--1581},
title = {{Hierarchical Dirichlet Processes}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33749249312&partnerID=tZOtx3y1},
volume = {101},
year = {2006}
}
@article{Bengio2013a,
author = {Bengio, Y and Courville, A},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Bengio, Courville_2013_Deep learning of representations.pdf:pdf},
journal = {Handbook on Neural Information Processing},
pages = {1--28},
title = {{Deep learning of representations}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-36657-4_1},
volume = {49},
year = {2013}
}
@misc{Seide,
author = {Seide, F. and Li, G. and Yu, D.},
booktitle = {Proc. Interspeech},
pages = {437--440},
title = {{Conversational speech transcription using context-dependent deep neural networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84858966230&partnerID=tZOtx3y1}
}
@misc{Seeger2004,
abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
author = {Seeger, Matthias},
booktitle = {International journal of neural systems},
issn = {01290657},
number = {2},
pages = {69--106},
title = {{Gaussian processes for machine learning.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-12444291490&partnerID=tZOtx3y1},
volume = {14},
year = {2004}
}
@article{Castrodad2012,
abstract = {An efficient sparse modeling pipeline for the classification of human actions from video is here developed. Spatio-temporal features that characterize local changes in the image are first extracted. This is followed by the learning of a class-structured dictionary encoding the individual actions of interest. Classification is then based on reconstruction, where the label assigned to each video comes from the optimal sparse linear combination of the learned basis vectors (action primitives) representing the actions. A low computational cost deep-layer model learning the inter-class correlations of the data is added for increasing discriminative power. In spite of its simplicity and low computational cost, the method outperforms previously reported results for virtually all standard datasets. © 2012 Springer Science+Business Media, LLC (outside the USA).},
author = {Castrodad, Alexey and Sapiro, Guillermo},
doi = {10.1007/s11263-012-0534-7},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
keywords = {Action classification,Dictionary learning,Sparse modeling,Supervised learning},
month = jun,
number = {1},
pages = {1--15},
title = {{Sparse Modeling of Human Actions from Motion Imagery}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861728486&partnerID=tZOtx3y1},
volume = {100},
year = {2012}
}
@article{Erhan2010,
abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
archivePrefix = {arXiv},
arxivId = {arXiv:1206.5538v1},
author = {Erhan, Dumitru and Courville, Aaron and Vincent, Pascal and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine Antoine and Vincent, Pascal and Bengio, Samy},
eprint = {arXiv:1206.5538v1},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Erhan et al._2010_Why Does Unsupervised Pre-training Help Deep Learning.pdf:pdf},
issn = {15324435},
journal = {The Journal of Machine Learning Research},
keywords = {AutoEnc,Deep architectures,Deep belief networks,GenDL,Non-convex optimization,Stacked denoising auto-encoders,Unsupervised,Unsupervised pre-training,deep architectures,deep belief networks,non-convex optimization,stacked denoising auto-encoders,unsupervised pre-training},
mendeley-tags = {AutoEnc,GenDL,Unsupervised},
month = mar,
pages = {625--660},
publisher = {JMLR.org},
title = {{Why Does Unsupervised Pre-training Help Deep Learning ?}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77949522811&partnerID=tZOtx3y1 http://dl.acm.org/citation.cfm?id=1756006.1756025 http://portal.acm.org/citation.cfm?id=1756025},
volume = {11},
year = {2010}
}
@article{Marinai2005,
abstract = {Artificial neural networks have been extensively applied to document analysis and recognition. Most efforts have been devoted to the recognition of isolated handwritten and printed characters with widely recognized successful results. However, many other document processing tasks, like preprocessing, layout analysis, character segmentation, word recognition, and signature verification, have been effectively faced with very promising results. This paper surveys the most significant problems in the area of offline document image processing, where connectionist-based approaches have been applied. Similarities and differences between approaches belonging to different categories are discussed. A particular emphasis is given on the crucial role of prior knowledge for the conception of both appropriate architectures and learning algorithms. Finally, the paper provides a critical analysis on the reviewed approaches and depicts the most promising research guidelines in the field. In particular, a second generation of connectionist-based models are foreseen which are based on appropriate graphical representations of the learning environment.},
author = {Marinai, Simone and Gori, Marco and Soda, Giovanni and Society, Computer},
doi = {10.1109/TPAMI.2005.4},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Marinai et al._2005_Artificial neural networks for document analysis and recognition.pdf:pdf},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Automatic Data Processing,Automatic Data Processing: methods,Computer Graphics,Computer-Assisted,Computer-Assisted: methods,Documentation,Handwriting,Image Enhancement,Image Enhancement: methods,Image Interpretation,Information Storage and Retrieval,Information Storage and Retrieval: methods,Neural Networks (Computer),Numerical Analysis,Pattern Recognition,Reading,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,User-Computer Interface},
month = jan,
number = {1},
pages = {23--35},
pmid = {15628266},
shorttitle = {Pattern Analysis and Machine Intelligence, IEEE Tr},
title = {{Artificial neural networks for document analysis and recognition.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15628266},
volume = {27},
year = {2005}
}
@inproceedings{Black2007,
abstract = {This paper gives a general overview of techniques in statistical parametric speech synthesis. One of the instances of these techniques, called HMM-based generation synthesis (or simply HMM-based synthesis), has recently been shown to be very effective in generating acceptable speech synthesis. This paper also contrasts these techniques with the more conventional unit selection technology that has dominated speech synthesis over the last ten years. Advantages and disadvantages of statistical parametric synthesis are highlighted as well as identifying where we expect the key developments to appear in the immediate future. © 2007 IEEE.},
author = {Black, Alan W and Zen, Heiga and Tokuda, Keiichi},
booktitle = {2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
doi = {10.1109/ICASSP.2007.367298},
isbn = {1-4244-0727-3},
issn = {15206149},
keywords = {Hidden Markov models,Speech synthesis},
pages = {IV--1229--IV--1232},
publisher = {IEEE},
title = {{Statistical Parametric Speech Synthesis}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34547526960&partnerID=tZOtx3y1},
volume = {4},
year = {2007}
}
@article{Schmidhuber2014,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, Juergen},
eprint = {1404.7828},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Schmidhuber_2014_Deep Learning in Neural Networks An Overview.pdf:pdf},
month = apr,
pages = {75},
title = {{Deep Learning in Neural Networks: An Overview}},
url = {http://arxiv.org/abs/1404.7828},
year = {2014}
}
@article{Merlo2001,
abstract = {Automatic acquisition of lexical knowledge is critical to a wide range of natural language processing tasks. Especially important is knowledge about verbs, which are the primary source of relational information in a sentence - the predicate-argument structure that relates an action or state to its participants (i.e., who did what to whom). In this work, we report on supervised learning experiments to automatically classify three major types of English verbs, based on their argument structure - specifically, the thematic roles they assign to participants. We use linguistically-motivated statistical indicators extracted from large annotated corpora to train the classifier, achieving 69.8% accuracy for a task whose baseline is 34%, and whose expert-based upper bound we calculate at 86.5%. A detailed analysis of the performance of the algorithm and of its errors confirms that the proposed features capture properties related to the argument structure of the verbs. Our results validate our hypotheses that knowledge about thematic relations is crucial for verb classification, and that it can be gleaned from a corpus by automatic means. We thus demonstrate an effective combination of deeper linguistic knowledge with the robustness and scalability of statistical techniques.},
author = {Merlo, Paola and Stevenson, Suzanne},
doi = {10.1162/089120101317066122},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Merlo, Stevenson_2001_Automatic Verb Classification Based on Statistical Distributions of Argument Structure.pdf:pdf},
issn = {0891-2017},
journal = {Computational Linguistics},
month = sep,
number = {3},
pages = {373--408},
title = {{Automatic Verb Classification Based on Statistical Distributions of Argument Structure}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0039190150&partnerID=tZOtx3y1},
volume = {27},
year = {2001}
}
@book{Hardle2004,
address = {Berlin, Heidelberg},
author = {H\"{a}rdle, Wolfgang and Werwatz, Axel and M\"{u}ller, Marlene and Sperlich, Stefan},
doi = {10.1007/978-3-642-17146-8},
isbn = {978-3-642-62076-8},
publisher = {Springer Berlin Heidelberg},
series = {Springer Series in Statistics},
title = {{Nonparametric and Semiparametric Models}},
url = {http://link.springer.com/10.1007/978-3-642-17146-8},
year = {2004}
}
@book{Yin2008,
abstract = {For many years, artificial neural networks (ANNs) have been studied and used to model information processing systems based on or inspired by biological neural structures. They not only can provide solutions with improved performance when compared with traditional problem-solving methods, but also give a deeper understanding of human cognitive abilities. Among various existing neural network architectures and learning algorithms, Kohonen's selforganizing map (SOM) [46] is one of the most popular neural network models. Developed for an associative memory model, it is an unsupervised learning algorithm with a simple structure and computational form, and is motivated by the retina-cortex mapping. Self-organization in general is a fundamental pattern recognition process, in which intrinsic inter- and intra-pattern relationships among the stimuli and responses are learnt without the presence of a potentially biased or subjective external influence. The SOM can provide topologically preserved mapping from input to output spaces. Although the computational form of the SOM is very simple, numerous researchers have already examined the algorithm and many of its problems, nevertheless research in this area goes deeper and deeper - there are still many aspects to be exploited. In this Chapter, we review the background, theories and statistical properties of this important learning model and present recent advances from various pattern recognition aspects through a number of case studies and applications. The SOM is optimal for vector quantization. Its topographical ordering provides the mapping with enhanced fault- and noise-tolerant abilities. It is also applicable to many other applications, such as dimensionality reduction, data visualization, clustering and classification. Various extensions of the SOM have been devised since its introduction to extend the mapping as effective solutions for a wide range of applications. Its connections with other learning paradigms and application aspects are also exploited. The Chapter is intended to serve as an updated, extended tutorial, a review, as well as a reference for advanced topics in the subject. © 2008 Springer-Verlag Berlin Heidelberg.},
address = {Berlin, Heidelberg},
author = {Yin, Hujun},
booktitle = {Computational intelligence: a compendium},
doi = {10.1007/978-3-540-78293-3},
editor = {Fulcher, John and Jain, L. C.},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Yin_2008_The self-organizing maps background, theories, extensions and applications.pdf:pdf},
isbn = {978-3-540-78292-6},
issn = {1860949X},
pages = {715--762},
publisher = {Springer Berlin Heidelberg},
series = {Studies in Computational Intelligence},
title = {{The self-organizing maps: background, theories, extensions and applications}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-44849094485&partnerID=tZOtx3y1},
volume = {115},
year = {2008}
}
@inproceedings{Le2014,
abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
archivePrefix = {arXiv},
arxivId = {1405.4053},
author = {Le, QV and Mikolov, Tomas},
booktitle = {International Conference on Machine Learning - ICML 2014},
eprint = {1405.4053},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Le, Mikolov_2014_Distributed Representations of Sentences and Documents.pdf:pdf},
isbn = {9781634393973},
pages = {1188--1196},
title = {{Distributed Representations of Sentences and Documents}},
url = {http://arxiv.org/abs/1405.4053},
volume = {32},
year = {2014}
}
@article{Deng2009a,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ldquoImageNetrdquo, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia Deng Jia and Dong, Wei Dong Wei and Socher, R. and Li, LJ Li-Jia Li Li-Jia and Li, Kai Li Kai and Fei-Fei, Li Fei-Fei Li},
doi = {10.1109/CVPR.2009.5206848},
isbn = {978-1-4244-3992-8},
issn = {1063-6919},
journal = {Computer Vision and Pattern Recognition},
pages = {248--255},
title = {{ImageNet: A large-scale hierarchical image database}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5206848},
year = {2009}
}
@inproceedings{Ranzato2008,
author = {Ranzato, Marc'aurelio and Boureau, Y-lan and Cun, Yann L.},
booktitle = {Advances in Neural Information Processing Systems},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Ranzato, Boureau, Cun_2008_Sparse Feature Learning for Deep Belief Networks.pdf:pdf},
keywords = {DBN},
mendeley-tags = {DBN},
pages = {1185--1192},
title = {{Sparse Feature Learning for Deep Belief Networks}},
url = {http://papers.nips.cc/paper/3363-sparse-feature-learning-for-deep-belief-networks},
year = {2008}
}
@article{Deng2014a,
abstract = {In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep learning. The previous and the updated materials cover both theory and applications, and analyze its future directions. The goal of this tutorial survey is to introduce the emerging area of deep learning or hierarchical learning to the APSIPA community. Deep learning refers to a class of machine learning techniques, developed largely since 2006, where many stages of non-linear information processing in hierarchical architectures are exploited for pattern classification and for feature learning. In the more recent literature, it is also connected to representation learning, which involves a hierarchy of features or concepts where higher- level concepts are defined from lower-level ones and where the same lower-level concepts help to define higher-level ones. In this tutorial survey, a brief history of deep learning research is discussed first. Then, a classificatory scheme is developed to analyze and summarize major work reported in the recent deep learning literature. Using this scheme, I provide a taxonomy-oriented survey on the existing deep architectures and algorithms in the literature, and categorize them into three classes: generative, discriminative, and hybrid. Three representative deep architectures – deep autoencoders, deep stacking networks with their generalization to the temporal domain (recurrent networks), and deep neural networks (pretrained with deep belief networks) – one in each of the three classes, are presented in more detail. Next, selected applications of deep learning are reviewed in broad areas of signal and information processing including audio/speech, image/vision, multimodality, language modeling, natural language processing, and information retrieval. Finally, future directions of deep learning are discussed and analyzed.},
author = {Deng, Li},
doi = {10.1017/atsip.2013.9},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng_2014_A tutorial survey of architectures, algorithms, and applications for deep learning(2).pdf:pdf;:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Deng_2014_A tutorial survey of architectures, algorithms, and applications for deep learning.pdf:pdf},
issn = {2048-7703},
journal = {APSIPA Transactions on Signal and Information Processing},
keywords = {algorithms,deep learning,information processing},
pages = {e2},
title = {{A tutorial survey of architectures, algorithms, and applications for deep learning}},
url = {http://journals.cambridge.org/abstract_S2048770313000097},
volume = {3},
year = {2014}
}
@article{Pang2008,
author = {Pang, B and Lee, L},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Pang, Lee_2008_Opinion mining and sentiment analysis.pdf:pdf},
journal = {Foundations and trends in information retrieval},
title = {{Opinion mining and sentiment analysis}},
url = {http://dl.acm.org/citation.cfm?id=1454712},
year = {2008}
}
@article{Bergstra2006,
abstract = {We present an algorithm that predicts musical genre and artist from an audio waveform. Our method uses the ensemble learner ADABOOST to select from a set of audio features that have been extracted from segmented audio and then aggregated. Our classifier proved to be the most effective method for genre classification at the recent MIREX 2005 international contests in music information extraction, and the second-best method for recognizing artists. This paper describes our method in detail, from feature extraction to song classification, and presents an evaluation of our method on three genre databases and two artist-recognition databases. Furthermore, we present evidence collected from a variety of popular features and classifiers that the technique of classifying features aggregated over segments of audio is better than classifying either entire songs or individual short-timescale features. © Springer Science + Business Media, LLC 2006.},
author = {Bergstra, James and Casagrande, Norman and Erhan, Dumitru and Eck, Douglas and K\'{e}gl, Bal\'{a}zs},
doi = {10.1007/s10994-006-9019-7},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {Artist recognition,Audio feature aggregation,Genre classification,MIREX,Multiclass ADABOOST},
month = jun,
number = {2-3},
pages = {473--484},
title = {{Aggregate features and ADABOOST for music classification}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33751531805&partnerID=tZOtx3y1},
volume = {65},
year = {2006}
}
@inproceedings{Salakhutdinov2007a,
address = {New York, New York, USA},
author = {Salakhutdinov, Ruslan and Mnih, Andriy and Hinton, Geoffrey},
booktitle = {Proceedings of the 24th international conference on Machine learning - ICML '07},
doi = {10.1145/1273496.1273596},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Salakhutdinov, Mnih, Hinton_2007_Restricted Boltzmann machines for collaborative filtering.pdf:pdf},
isbn = {9781595937933},
keywords = {DBN},
mendeley-tags = {DBN},
month = jun,
pages = {791--798},
publisher = {ACM Press},
title = {{Restricted Boltzmann machines for collaborative filtering}},
url = {http://dl.acm.org/citation.cfm?id=1273496.1273596},
year = {2007}
}
@article{Hinton2002,
abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual "expert" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called "contrastive divergence" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
author = {Hinton, Geoffrey E},
doi = {10.1162/089976602760128018},
isbn = {10.1162/089976602760128018},
issn = {0899-7667},
journal = {Neural computation},
pages = {1771--1800},
pmid = {12180402},
title = {{Training products of experts by minimizing contrastive divergence.}},
volume = {14},
year = {2002}
}
@article{Arel2010,
author = {Arel, Itamar and Rose, DC and Karnowski, TP},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Arel, Rose, Karnowski_2010_Deep machine learning-a new frontier in artificial intelligence research.pdf:pdf},
journal = {Computational Intelligence \ldots},
number = {November},
pages = {13--18},
title = {{Deep machine learning-a new frontier in artificial intelligence research}},
url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5605630},
year = {2010}
}
@article{Mohamed2012,
abstract = {Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.},
author = {Mohamed, Abdel-rahman and Dahl, George E. and Hinton, Geoffrey},
doi = {10.1109/TASL.2011.2109382},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Mohamed, Dahl, Hinton_2012_Acoustic Modeling Using Deep Belief Networks.pdf:pdf},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
keywords = {Acoustic modeling,Artificial neural networks,Computational modeling,DBN,Data models,Gaussian mixture models,Hidden Markov models,Speech,Speech recognition,TIMIT dataset,Training,acoustic modeling,backpropagation,belief networks,deep belief networks (DBNs),discriminative fine-tuning,emission distribution,hidden Markov models,monophone hidden Markov models,multilayer generative model,neural nets,neural networks,phone recognition,probability distribution,spectral feature vectors,speech recognition,statistical distributions},
mendeley-tags = {DBN},
month = jan,
number = {1},
pages = {14--22},
shorttitle = {Audio, Speech, and Language Processing, IEEE Trans},
title = {{Acoustic Modeling Using Deep Belief Networks}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84055211743&partnerID=tZOtx3y1 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5704567},
volume = {20},
year = {2012}
}
@inproceedings{Mobahi2009,
abstract = {This work proposes a learning method for deep architectures that takes advantage of sequential data, in particular from the temporal coherence that naturally exists in unlabeled video recordings. That is, two successive frames are likely to contain the same object or objects. This coherence is used as a supervisory signal over the unlabeled data, and is used to improve the performance on a supervised task of interest. We demonstrate the effectiveness of this method on some pose invariant object and face recognition tasks.},
author = {Mobahi, Hossein and Collobert, Ronan and Weston, Jason},
booktitle = {Proceedings of the 26th International Conference On Machine Learning, ICML 2009},
isbn = {9781605585161},
pages = {737--744},
title = {{Deep learning from temporal coherence in video}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-71149084945&partnerID=tZOtx3y1},
year = {2009}
}
@article{Sabou2005,
abstract = {High quality domain ontologies are essential for successful employment of semantic Web services. However, their acquisition is difficult and costly, thus hampering the development of this field. In this paper we report on the first stage of research that aims to develop (semi-)automatic ontology learning tools in the context of Web services that can support domain experts in the ontology building task. The goal of this first stage was to get a better understanding of the problem at hand and to determine which techniques might be feasible to use. To this end, we developed a framework for (semi-)automatic ontology learning from textual sources attached to Web services. The framework exploits the fact that these sources are expressed in a specific sublanguage, making them amenable to automatic analysis. We implement two methods in this framework, which differ in the complexity of the employed linguistic analysis. We evaluate the methods in two different domains, verifying the quality of the extracted ontologies against high quality hand-built ontologies of these domains. Our evaluation lead to a set of valuable conclusions on which further work can be based. First, it appears that our method, while tailored for the Web services context, might be applicable across different domains. Second, we concluded that deeper linguistic analysis is likely to lead to better results. Finally, the evaluation metrics indicate that good results can be achieved using only relatively simple, off the shelf techniques. Indeed, the novelty of our work is not in the used natural language processing methods but rather in the way they are put together in a generic framework specialized for the context of Web services. © 2005 Elsevier B.V. All rights reserved.},
author = {Sabou, Marta and Wroe, Chris and Goble, Carole and Stuckenschmidt, Heiner},
doi = {10.1016/j.websem.2005.09.008},
issn = {15708268},
journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
keywords = {Ontology learning,Ontology learning evaluation,Semantic Web services},
month = dec,
number = {4},
pages = {340--365},
title = {{Learning domain ontologies for semantic Web service descriptions}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-28044452224&partnerID=tZOtx3y1},
volume = {3},
year = {2005}
}
@article{Dahl2012,
abstract = {We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively. © 2011 IEEE.},
author = {Dahl, G. E. and Acero, A.},
doi = {10.1109/TASL.2011.2134090},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing},
keywords = {Artificial neural network-hidden Markov model (ANN,context-dependent phone,deep belief network,deep neural network hidden Markov model (DNN-HMM),large-vocabulary speech recognition (LVSR),speech recognition},
month = jan,
number = {1},
pages = {30--42},
title = {{Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84055222005&partnerID=tZOtx3y1},
volume = {20},
year = {2012}
}
@inproceedings{Salakhutdinov2010,
abstract = {When modeling high-dimensional richly structured data, it is often the case that the distribution defined by the Deep Boltzmann Machine (DBM) has a rough energy landscape with many local minima separated by high energy barriers. The commonly used Gibbs sampler tends to get trapped in one local mode, which often results in unstable learning dynamics and leads to poor parameter estimates. In this paper, we concentrate on learning DBM's using adaptive MCMC algorithms. We first show a close connection between Fast PCD and adaptive MCMC. We then develop a Coupled Adaptive Simulated Tempering algorithm that can be used to better explore a highly multimodal energy landscape. Finally, we demonstrate that the proposed algorithm considerably improves parameter estimates, particularly when learning large-scale DBM's. Copyright 2010 by the author(s)/owner(s).},
author = {Salakhutdinov, Ruslan},
booktitle = {ICML 2010 - Proceedings, 27th International Conference on Machine Learning},
isbn = {9781605589077},
pages = {943--950},
title = {{Learning Deep Boltzmann Machines using adaptive MCMC}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-77956506016&partnerID=tZOtx3y1},
year = {2010}
}
@article{Ferragina2005,
abstract = {We provide a general boosting technique for Textual Data Compression. Qualitatively, it takes a good compression algorithm and turns it into an algorithm with a better compression performance guarantee. It displays the following remarkable properties: (a) it can turn any memoryless compressor into a compression algorithm that uses the "best possible" contexts; (b) it is very simple and optimal in terms of time; and (c) it admits a decompression algorithm again optimal in time. To the best of our knowledge, this is the first boosting technique displaying these properties. Technically, our boosting technique builds upon three main ingredients: the Burrows-Wheeler Transform, the Suffix Tree data structure, and a greedy algorithm to process them. Specifically, we show that there exists a proper partition of the Burrows-Wheeler Transform of a string 5 that shows a deep combinatorial relation with the kth order entropy of s. That partition can be identified via a greedy processing of the suffix tree of s with the aim of minimizing a proper objective function over its nodes. The final compressed string is then obtained by compressing individually each substring of the partition by means of the base compressor we wish to boost. Our boosting technique is inherently combinatorial because it does not need to assume any prior probabilistic model about the source emitting s, and it does not deploy any training, parameter estimation and learning. Various corollaries are derived from this main achievement. Among the others, we show analytically that using our booster, we get better compression algorithms than some of the best existing ones, that is, LZ77, LZ78, PPMC and the ones derived from the Burrows-Wheeler Transform. Further, we settle analytically some long-standing open problems about the algorithmic structure and the performance of BWT-based compressors. Namely, we provide the first family of BWT algorithms that do not use Move-To-Front or Symbol Ranking as a part of the compression process.© 2005 ACM.},
author = {Ferragina, Paolo and Giancarlo, Raffaele and Manzini, Giovanni and Sciortino, Marinella},
doi = {10.1145/1082036.1082043},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Arithmetic coding,Burrows-Wheeler transform,Empirical entropy,Huffman coding,Lempel-Ziv compressors,Suffix tree,Text compression},
month = jul,
number = {4},
pages = {688--713},
title = {{Boosting textual compression in optimal linear time}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-30544455566&partnerID=tZOtx3y1},
volume = {52},
year = {2005}
}
@article{Ciresan2012a,
abstract = {We describe the approach that won the final phase of the German traffic sign recognition benchmark. Our method is the only one that achieved a better-than-human recognition rate of 99.46%. We use a fast, fully parameterizable GPU implementation of a Deep Neural Network (DNN) that does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. Combining various DNNs trained on differently preprocessed data into a Multi-Column DNN (MCDNN) further boosts recognition performance, making the system insensitive also to variations in contrast and illumination.},
author = {Cireşan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, J\"{u}rgen},
doi = {10.1016/j.neunet.2012.02.023},
issn = {1879-2782},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Automatic Data Processing,Automobile Driving,Automobile Driving: psychology,Computer Graphics,Motor Vehicles,Neural Networks (Computer),Pattern Recognition, Automated,Vision, Ocular,Vision, Ocular: physiology},
month = aug,
pages = {333--8},
pmid = {22386783},
title = {{Multi-column deep neural network for traffic sign classification.}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84861776914&partnerID=tZOtx3y1},
volume = {32},
year = {2012}
}
@article{Srivastava2014,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:C\:/Users/Lampridis/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Srivastava et al._2014_Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
url = {http://jmlr.org/papers/v15/srivastava14a.html},
volume = {15},
year = {2014}
}
